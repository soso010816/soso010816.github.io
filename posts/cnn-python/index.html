<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>DL：CNN With Python | Soso's Blog</title><meta name=keywords content><meta name=description content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><meta name=author content="Cheng Liu"><link rel=canonical href=https://soso010816.github.io/posts/cnn-python/><link crossorigin=anonymous href=/assets/css/stylesheet.min.26833467d0a8d69309e10439aa8f9d66fab9e2ac88264732a9f9f62a15aefe51.css integrity="sha256-JoM0Z9Co1pMJ4QQ5qo+dZvq54qyIJkcyqfn2KhWu/lE=" rel="preload stylesheet" as=style><link rel=preload href=/head.jpg as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.e85ad0406048e8176e1c7661b25d5c69297ddfe41dc4124cf75ecb99a4f7b3d1.js integrity="sha256-6FrQQGBI6BduHHZhsl1caSl93+QdxBJM917LmaT3s9E=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://soso010816.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soso010816.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soso010816.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soso010816.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soso010816.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="DL：CNN With Python"><meta property="og:description" content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><meta property="og:type" content="article"><meta property="og:url" content="https://soso010816.github.io/posts/cnn-python/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-29T23:11:19+08:00"><meta property="article:modified_time" content="2022-08-29T23:11:19+08:00"><meta property="og:site_name" content="Soso's Resume"><meta name=twitter:card content="summary"><meta name=twitter:title content="DL：CNN With Python"><meta name=twitter:description content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soso010816.github.io/posts/"},{"@type":"ListItem","position":2,"name":"DL：CNN With Python","item":"https://soso010816.github.io/posts/cnn-python/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"DL：CNN With Python","name":"DL：CNN With Python","description":"“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog","keywords":[],"articleBody":" “ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog为大家带来鄙人封装的卷积神经网络python代码，供大家处理基本的图片分类预测问题并将结果进行可视化，当然大家也可以根据自己需求修改代码中的parames参数，从而选择出预测效果最佳的模型。 “ CNN的基本原理 ” 关于CNN的基本介绍大家可以在 A Simple Introduction About CNN 里进行学习。\n“ python代码 ” 本次的卷积神经网络使用的pytorch包，只要求有友友所使用的训练图片数据集标记好并放至所在的文件夹目录，即可以运行鄙人的CNN函数。并且一般卷积神经网络（CNN）主要用于图像处理技术， 因此本代码针对的数据集为 jpg、png等图片数据。\n导入所需的库 pytorch、glob、numpy、sklearn、matplotlib、copy\nimport torch\rimport torch.nn as nn\rimport torch.nn.functional as F\rfrom torch import optim\rfrom torchvision import utils\rfrom torch.optim.lr_scheduler import ReduceLROnPlateau\rfrom torchvision import datasets, models, transforms\rfrom torch.utils.data import DataLoader, Dataset\rimport copy\rimport glob\rimport numpy as np\rimport plotly.graph_objs as go\rimport matplotlib.pyplot as plt\rfrom plotly.subplots import make_subplots\rfrom sklearn.model_selection import train_test_split\r%matplotlib inline\r数据集的构建 CPU or CUDA\n# 1. 选择 CPU 还是 GPU 版的 pytorch 进行建模\rdevice = 'cuda' if torch.cuda.is_available() else 'cpu'\r# 2. 设置随机种子\rtorch.manual_seed(816)\rif device =='cuda':\rtorch.cuda.manual_seed_all(816)\r# 将所有图片数据的路径存储至列表中, train_dir和 test_dir为训练集图片和验证集图片所在的文件夹\rtrain_list = glob.glob(os.path.join(train_dir,'*.jpg')) # 如果图片为png形式，则将jpg改成png即可\rtest_list = glob.glob(os.path.join(test_dir, '*.jpg')) # 如果有测试集则使用这行代码，否则可以删除\r模型的搭建 数据增强、模型结构设计、模型的训练与保持、结果可视化\n# 3. 定义完整的 CNN 框架模型\rdef So_CNN_model(train_list, test_list = None):\r# 训练集和验证集的分割\rtrain_list, val_list = train_test_split(train_list, test_size=0.2)\r# 4. 图片的预处理，图片增强\rtrain_transforms = transforms.Compose([\rtransforms.Resize((224, 224)), # 设计训练图片转化为224*224图片大小，可以根据需求自行修改大小\rtransforms.RandomResizedCrop(224),\rtransforms.RandomHorizontalFlip(),\rtransforms.ToTensor(),\r])\rval_transforms = transforms.Compose([\rtransforms.Resize((224, 224)), # 设计验证集图片转化为224*224图片大小\rtransforms.RandomResizedCrop(224),\rtransforms.RandomHorizontalFlip(),\rtransforms.ToTensor(),\r])\r# 如果有测试集需要输出，则也对验证集进行图片转化增强\rif test_list != None:\rtest_transforms = transforms.Compose([ transforms.Resize((224, 224)),\rtransforms.RandomResizedCrop(224),\rtransforms.RandomHorizontalFlip(),\rtransforms.ToTensor()\r])\r# 5. 定义一个类进行数据转化、图片数据集的处理、以及图片的标注转化\rclass dataset(torch.utils.data.Dataset):\rdef __init__(self, file_list, transform=None):\rself.file_list = file_list # 图片名字列表\rself.transform = transform # 转化器\rself.label_list = label_list # 所有的标签种类\rdef __len__(self):\rself.filelength = len(self.file_list)\rreturn self.filelength # 图片数目\r# 对于本地图片的下载与标注\rdef __getitem__(self,idx):\rimg_path = self.file_list[idx]\rimg = Image.open(img_path) # 打开本地图片数据集所在的位置\rimg_transformed = self.transform(img) # 数据增强\rlabel = img_path.split('/')[-1].split('.')[0] # 对图片名字分割，前提是图片名字即为标注\rlabel = label_list.index(label) # 搜索该标签在列表中的位置，并将其进行数值标注，有几个种类数值就有几种\rreturn img_transformed, label\r# 6. 定义各个类\rtrain_data = dataset(train_list, transform=train_transforms)\rif test_list != None:\rtest_data = dataset(test_list, transform=test_transforms)\rval_data = dataset(val_list, transform=test_transforms)\r# 7. 数据加载\rbatch_size = 100\rtrain_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True )\rif test_list != None:\rtest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True)\rval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True)\r# 8. CNN模型架构的设计\rclass Cnn(nn.Module):\rdef __init__(self):\rsuper(Cnn,self).__init__()\r'''以下所有层的结构参数和层数数量都可以进行需修改\r可以比较参数不同产生的模型结果，从而选择最优参数'''\rc,h,w = params['shape_in'] # 初始 数据结构\rf = params['initial_filters'] # 初始 数据转化的层数\rnum_classes = params['num_classes'] # 需要分类的总数\rnum_fc1 = params['num_fc1'] # 全连接层的第一层\rdropout_rate = params['dropout_rate']\r# 第一层卷积层，将3通道 c 维数据转化为 f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0\rself.layer1 = nn.Sequential(\rnn.Conv2d(c, f, kernel_size = 3, padding=0, stride=2),\rnn.BatchNorm2d(f), # f 维 数据进行标准化处理\rnn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择\rnn.MaxPool2d(2) # 池化层，2*2 矩阵大小进行池化\r)\r# 第一层后，转化得到的维度\rh,w = findConv2dOutShape(h, w, nn.MaxPool2d(2))\rh,w = h/2, w/2\r# 第二层卷积层，将 f 维数据转化为 2*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0\rself.layer2 = nn.Sequential(\rnn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2),\rnn.BatchNorm2d(2*f), # 2*f 维 数据进行标准化处理\rnn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择\rnn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化\r)\r# 第二层后，转化得到的维度\rh,w = findConv2dOutShape(h, w, nn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2))\rh,w = h/2, w/2\r# 第三层卷积层，将 32 维数据转化为 64 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0\rself.layer3 = nn.Sequential(\rnn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2),\rnn.BatchNorm2d(4*f), # 4*f 维 数据进行标准化处理\rnn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择\rnn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化\r)\r# 第三层后，转化得到的维度\th,w = findConv2dOutShape(h, w, nn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2))\rh,w = h/2, w/2\r# 第四层卷积层，将 4*f 维数据转化为 8*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0\rself.layer4 = nn.Sequential(\rnn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2),\rnn.BatchNorm2d(8*f), # 8*f 维 数据进行标准化处理\rnn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择\rnn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化\r)\r# 第四层后，转化得到的维度\rh,w = findConv2dOutShape(h, w, nn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2)) h,w = h/2, w/2\r# 最后 我设计了2层全连接神经网络结构\rself.num_flatten= h * w* 8*f\rself.fc1 = nn.Linear(self.num_flatten, num_fc1) self.dropout = nn.Dropout(dropout_rate) # 以 0.5 的概率对其进行剔除\rself.fc2 = nn.Linear(num_fc1, num_class)\rself.relu = nn.ReLU() # 定义激活函数 RELU\rself.softmax = nn.log_softmax() # 定义 最后的输出函数 Softmax\r# 定义向前传播\rdef forward(self,x):\rout = self.layer1(x)\rout = self.layer2(out)\rout = self.layer3(out)\rout = self.layer4(out)\rout = out.view(-1, self.num_flatten)\rout = self.relu(self.fc1(out))\rout = self.softmax(self.fc2(out), dim = 1)\rreturn out\rparams_model={\r\"shape_in\": (3, 224, 224), \"initial_filters\": 8, \"num_fc1\": 100,\r\"dropout_rate\": 0.25,\r\"num_classes\": len(label_list)} # num_class,根据类别的总数而定\r# 传达模型结构给cnn_model\rcnn_model = Cnn(params_model)\rdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\rmodel = cnn_model.to(device)\r# 9. 定义损失函数\rloss_func = nn.NLLLoss(reduction=\"sum\")\r# 10. 定义一个优化器，优化器将保持当前状态，并根据计算的梯度更新参数\ropt = optim.Adam(cnn_model.parameters(), lr=3e-4)\rlr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)\r# 11. 定义模型训练函数\rdef train_val(model, params,verbose=False):\r# 获取训练参数\repochs = params[\"epochs\"]\rloss_func = params[\"loss_func\"]\ropt = params[\"optimiser\"]\rtrain_dl = params[\"train\"]\rval_dl = params[\"val\"]\rcheck = params[\"check\"]\rlr_scheduler = params[\"lr_change\"]\rweight_path = params[\"weight_path\"]\rloss_history = {\"train\": [],\"val\": []} # 每次 epoch 的训练集和验证集的损失值\rmetric_history = {\"train\": [],\"val\": []} # 每次 epoch 的 metric值\rbest_model_wts = copy.deepcopy(model.state_dict()) # 深度复制最佳性能模型的权重\rbest_loss = float('inf') # 将最佳的损失值初始化为极大值\r# 迭代循环\rfor epoch in range(epochs):\r# 获取学习率\rcurrent_lr = get_lr(opt)\rif(verbose):\rprint('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))\r# 使用训练集训练 CNN 模型\rmodel.train()\rtrain_loss, train_metric = loss_epoch(model,loss_func,train_dl,check,opt)\r# 收集训练数据集的损失和衡量标准\rloss_history[\"train\"].append(train_loss)\rmetric_history[\"train\"].append(train_metric)\r# 使用验证集对模型结果进行评估\rmodel.eval()\rwith torch.no_grad():\rval_loss, val_metric = loss_epoch(model, loss_func, val_dl,check)\r# 选择最好的参数模型\rif val_loss \u003c best_loss:\rbest_loss = val_loss\rbest_model_wts = copy.deepcopy(model.state_dict())\r# 存储模型参数至本地文件\rtorch.save(model.state_dict(), weight_path)\rif(verbose):\rprint(\"已经保存完训练得到的最好模型！\")\r# 存储验证数据集的损失和衡量标准\rloss_history[\"val\"].append(val_loss)\rmetric_history[\"val\"].append(val_metric)\r# 学习率筛选\rlr_scheduler.step(val_loss)\rif current_lr != get_lr(opt):\rif(verbose):\rprint(\"已经加载完CNN模型！\")\rmodel.load_state_dict(best_model_wts) if(verbose):\rprint(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\rprint(\"-\"*10) # 存储模型的权重和参数数据至本地\rmodel.load_state_dict(best_model_wts)\rreturn model, loss_history, metric_history\rparams_train={\r\"train\": train_dl,\"val\": val_dl,\r\"epochs\": 50, # 迭代 50 次\r\"optimiser\": optim.Adam(cnn_model.parameters(),\rlr=3e-4),\r\"lr_change\": ReduceLROnPlateau(opt,\rmode = 'min',\rfactor = 0.5,\rpatience = 20,\rverbose = 0),\r\"loss_func\": nn.NLLLoss(reduction = \"sum\"),\r\"weight_path\": \"weights.pt\",\r\"check\": False, }\r# 训练和验证模型\rcnn_model,loss_hist,metric_hist = train_val(cnn_model, params_train)\r# 训练参数进程\repochs = params_train[\"epochs\"]\r# 绘制结果图\rfig = make_subplots(rows = 1, cols = 2, subplot_titles = ['损失值-折线图','准确率-折线图'])\rfig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[\"train\"], name = '训练集的损失值'), row = 1, col = 1)\rfig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[\"val\"], name = '验证集的损失值'), row = 1, col = 1)\rfig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[\"train\"], name = '训练集的准确率'), row = 1, col = 2)\rfig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[\"val\"], name = '验证集的准确率'), row = 1, col = 2)\rfig.update_layout(template = 'plotly_white'); fig.update_layout(margin = {\"r\":0,\"t\":60,\"l\":0,\"b\":0}, height= 300)\rfig.show()\rSo_CNN_model(train_list, test_list)\r感谢各位友友能看到最后！附一张我超级喜欢的数学宇宙gif代表结束！\nThe End！\n","wordCount":"2518","inLanguage":"en","datePublished":"2022-08-29T23:11:19+08:00","dateModified":"2022-08-29T23:11:19+08:00","author":{"@type":"Person","name":"Cheng Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soso010816.github.io/posts/cnn-python/"},"publisher":{"@type":"Organization","name":"Soso's Blog","logo":{"@type":"ImageObject","url":"https://soso010816.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soso010816.github.io/ accesskey=h title="Soso's Blog (Alt + H)"><img src=https://soso010816.github.io/head.jpg alt=logo aria-label=logo height=25>Soso's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://soso010816.github.io/ title="💕So Home"><span>💕So Home</span></a></li><li><a href=https://soso010816.github.io/posts/ title="👍So Posts"><span>👍So Posts</span></a></li><li><a href=https://soso010816.github.io/archive/ title="✌️So Archive"><span>✌️So Archive</span></a></li><li><a href=https://soso010816.github.io/search/ title="🐺So Search (Alt + /)" accesskey=/><span>🐺So Search</span></a></li><li><a href=https://soso010816.github.io/tags/ title="👻So Tags"><span>👻So Tags</span></a></li><li><a href=https://soso010816.github.io/about/ title="😍About Me"><span>😍About Me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soso010816.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://soso010816.github.io/posts/>Posts</a></div><h1 class=post-title>DL：CNN With Python</h1><div class=post-meta><span title='2022-08-29 23:11:19 +0800 CST'>August 29, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Cheng Liu</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#-%e7%ae%80%e5%8d%95%e7%9a%84%e4%bb%8b%e7%bb%8d- aria-label="“ 简单的介绍 ”"><strong>“ 简单的介绍 ”</strong></a></li><li><a href=#-cnn%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86- aria-label="“ CNN的基本原理 ”"><strong>“ CNN的基本原理 ”</strong></a></li><li><a href=#-python%e4%bb%a3%e7%a0%81- aria-label="“ python代码 ”"><strong>“ python代码 ”</strong></a></li></ul></div></details></div><div class=post-content><p><img loading=lazy src=https://visme.co/blog/wp-content/uploads/2019/09/interactive-presentation-header.gif alt=" "></p><h3 id=-简单的介绍-><strong>“ 简单的介绍 ”</strong><a hidden class=anchor aria-hidden=true href=#-简单的介绍->#</a></h3><blockquote><p>在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog为大家带来鄙人封装的卷积神经网络python代码，供大家处理基本的图片分类预测问题并将结果进行可视化，当然大家也可以根据自己需求修改代码中的parames参数，从而选择出预测效果最佳的模型。
<img loading=lazy src=https://thumbs.gfycat.com/WhichMetallicDodo-size_restricted.gif alt=" "></p></blockquote><h3 id=-cnn的基本原理-><strong>“ CNN的基本原理 ”</strong><a hidden class=anchor aria-hidden=true href=#-cnn的基本原理->#</a></h3><blockquote><p>关于CNN的基本介绍大家可以在 <a href=https://zhuanlan.zhihu.com/p/42559190>A Simple Introduction About CNN</a> 里进行学习。</p></blockquote><h3 id=-python代码-><strong>“ python代码 ”</strong><a hidden class=anchor aria-hidden=true href=#-python代码->#</a></h3><blockquote><p>本次的卷积神经网络使用的pytorch包，只要求有友友所使用的训练图片数据集标记好并放至所在的文件夹目录，即可以运行鄙人的CNN函数。并且一般卷积神经网络（CNN）主要用于图像处理技术， 因此本代码针对的数据集为 jpg、png等图片数据。</p></blockquote><ul><li><strong>导入所需的库</strong></li></ul><blockquote><p>pytorch、glob、numpy、sklearn、matplotlib、copy</p></blockquote><pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import optim
from torchvision import utils
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader, Dataset

import copy
import glob
import numpy as np
import plotly.graph_objs as go
import matplotlib.pyplot as plt
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split
%matplotlib inline
</code></pre><ul><li><strong>数据集的构建</strong></li></ul><blockquote><p>CPU or CUDA</p></blockquote><pre><code># 1. 选择 CPU 还是 GPU 版的 pytorch 进行建模
device = 'cuda' if torch.cuda.is_available() else 'cpu'

# 2. 设置随机种子
torch.manual_seed(816)
if device =='cuda':
    torch.cuda.manual_seed_all(816)

# 将所有图片数据的路径存储至列表中, train_dir和 test_dir为训练集图片和验证集图片所在的文件夹
train_list = glob.glob(os.path.join(train_dir,'*.jpg')) # 如果图片为png形式，则将jpg改成png即可
test_list = glob.glob(os.path.join(test_dir, '*.jpg')) # 如果有测试集则使用这行代码，否则可以删除
</code></pre><ul><li><strong>模型的搭建</strong></li></ul><blockquote><p>数据增强、模型结构设计、模型的训练与保持、结果可视化</p></blockquote><pre><code># 3. 定义完整的 CNN 框架模型
def So_CNN_model(train_list, test_list = None):

	# 训练集和验证集的分割
	train_list, val_list = train_test_split(train_list, test_size=0.2)
	
	# 4. 图片的预处理，图片增强
	train_transforms =  transforms.Compose([
	        transforms.Resize((224, 224)), # 设计训练图片转化为224*224图片大小，可以根据需求自行修改大小
	        transforms.RandomResizedCrop(224),
	        transforms.RandomHorizontalFlip(),
	        transforms.ToTensor(),
	    ])

	val_transforms = transforms.Compose([
	        transforms.Resize((224, 224)), # 设计验证集图片转化为224*224图片大小
	        transforms.RandomResizedCrop(224),
	        transforms.RandomHorizontalFlip(),
	        transforms.ToTensor(),
	    ])
	
	# 如果有测试集需要输出，则也对验证集进行图片转化增强
	if test_list != None:
			test_transforms = transforms.Compose([   
			    transforms.Resize((224, 224)),
			    transforms.RandomResizedCrop(224),
			    transforms.RandomHorizontalFlip(),
			    transforms.ToTensor()
			    ])

	# 5. 定义一个类进行数据转化、图片数据集的处理、以及图片的标注转化
	class dataset(torch.utils.data.Dataset):
	
		def __init__(self, file_list, transform=None):
	
	        self.file_list = file_list # 图片名字列表
	        self.transform = transform  # 转化器
	        self.label_list = label_list # 所有的标签种类
	
	    def __len__(self):

	        self.filelength = len(self.file_list)
	        return self.filelength  # 图片数目
	    
	    # 对于本地图片的下载与标注
	    def __getitem__(self,idx):
	        img_path = self.file_list[idx]
	        img = Image.open(img_path)  # 打开本地图片数据集所在的位置
	        img_transformed = self.transform(img)  # 数据增强
	        
	        label = img_path.split('/')[-1].split('.')[0] # 对图片名字分割，前提是图片名字即为标注
					label = label_list.index(label) # 搜索该标签在列表中的位置，并将其进行数值标注，有几个种类数值就有几种
	            
	        return img_transformed, label

	# 6. 定义各个类
	train_data = dataset(train_list, transform=train_transforms)
	if test_list != None:
			test_data = dataset(test_list, transform=test_transforms)
	val_data = dataset(val_list, transform=test_transforms)

	# 7. 数据加载
	batch_size = 100
	train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True )
	if test_list != None:
			test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True)
	val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True)

	# 8. CNN模型架构的设计
	class Cnn(nn.Module):

	    def __init__(self):

	    	super(Cnn,self).__init__()
	
		'''以下所有层的结构参数和层数数量都可以进行需修改
		可以比较参数不同产生的模型结果，从而选择最优参数'''

		c,h,w = params['shape_in'] # 初始 数据结构
		f = params['initial_filters'] # 初始 数据转化的层数
		num_classes = params['num_classes']  # 需要分类的总数
		num_fc1 =  params['num_fc1'] # 全连接层的第一层
		dropout_rate = params['dropout_rate']

		# 第一层卷积层，将3通道 c 维数据转化为 f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0
	        self.layer1 = nn.Sequential(
	            nn.Conv2d(c, f, kernel_size = 3, padding=0, stride=2),
	            nn.BatchNorm2d(f),  # f 维 数据进行标准化处理
	            nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择
	            nn.MaxPool2d(2) # 池化层，2*2 矩阵大小进行池化
	        )
	
		# 第一层后，转化得到的维度
	        h,w = findConv2dOutShape(h, w, nn.MaxPool2d(2))
		h,w = h/2, w/2

		# 第二层卷积层，将 f 维数据转化为 2*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0
	        self.layer2 = nn.Sequential(
	            nn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2),
	            nn.BatchNorm2d(2*f), # 2*f 维 数据进行标准化处理
	            nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择
	            nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化
	            )
	
		# 第二层后，转化得到的维度
	        h,w = findConv2dOutShape(h, w, nn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2))
		h,w = h/2, w/2

		# 第三层卷积层，将 32 维数据转化为 64 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0
	        self.layer3 = nn.Sequential(
	            nn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2),
	            nn.BatchNorm2d(4*f), # 4*f 维 数据进行标准化处理
	            nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择
	            nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化
	        )
	
		# 第三层后，转化得到的维度	
	        h,w = findConv2dOutShape(h, w, nn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2))
		h,w = h/2, w/2

		# 第四层卷积层，将 4*f 维数据转化为 8*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0
	        self.layer4 = nn.Sequential(
	            nn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2),
	            nn.BatchNorm2d(8*f), # 8*f 维 数据进行标准化处理
	            nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择
	            nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化
	        )
	
		# 第四层后，转化得到的维度
	        h,w = findConv2dOutShape(h, w, nn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2))        
		h,w = h/2, w/2

		# 最后 我设计了2层全连接神经网络结构
		self.num_flatten= h * w* 8*f
	        self.fc1 = nn.Linear(self.num_flatten, num_fc1)  
	        self.dropout = nn.Dropout(dropout_rate) # 以 0.5 的概率对其进行剔除
	        self.fc2 = nn.Linear(num_fc1, num_class)
	        self.relu = nn.ReLU() # 定义激活函数  RELU
		self.softmax = nn.log_softmax() # 定义 最后的输出函数 Softmax
	
	    # 定义向前传播
	    def forward(self,x):
	        out = self.layer1(x)
	        out = self.layer2(out)
	        out = self.layer3(out)
		out = self.layer4(out)
	        out = out.view(-1, self.num_flatten)
	        out = self.relu(self.fc1(out))
		out = self.softmax(self.fc2(out), dim = 1)
	
	        return out
	
	params_model={
	        &quot;shape_in&quot;: (3, 224, 224), 
	        &quot;initial_filters&quot;: 8,    
	        &quot;num_fc1&quot;: 100,
	        &quot;dropout_rate&quot;: 0.25,
	        &quot;num_classes&quot;: len(label_list)}  # num_class,根据类别的总数而定

	# 传达模型结构给cnn_model
	cnn_model = Cnn(params_model)
	device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
	model = cnn_model.to(device)

	# 9. 定义损失函数
	loss_func = nn.NLLLoss(reduction=&quot;sum&quot;)
		
	# 10. 定义一个优化器，优化器将保持当前状态，并根据计算的梯度更新参数
	opt = optim.Adam(cnn_model.parameters(), lr=3e-4)
	lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)

	# 11. 定义模型训练函数
	def train_val(model, params,verbose=False):

	    # 获取训练参数
	    epochs = params[&quot;epochs&quot;]
	    loss_func = params[&quot;loss_func&quot;]
	    opt = params[&quot;optimiser&quot;]
	    train_dl = params[&quot;train&quot;]
	    val_dl = params[&quot;val&quot;]
	    check = params[&quot;check&quot;]
	    lr_scheduler = params[&quot;lr_change&quot;]
	    weight_path = params[&quot;weight_path&quot;]
	  
	    loss_history = {&quot;train&quot;: [],&quot;val&quot;: []} # 每次 epoch 的训练集和验证集的损失值
	    metric_history = {&quot;train&quot;: [],&quot;val&quot;: []} # 每次 epoch 的 metric值
	    best_model_wts = copy.deepcopy(model.state_dict()) # 深度复制最佳性能模型的权重
	    best_loss = float('inf') # 将最佳的损失值初始化为极大值

	    # 迭代循环
	    for epoch in range(epochs):
	        
	        # 获取学习率
	        current_lr = get_lr(opt)
	        if(verbose):
	            print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr))
	        
	        # 使用训练集训练 CNN 模型
	        model.train()
	        train_loss, train_metric = loss_epoch(model,loss_func,train_dl,check,opt)
	
	        # 收集训练数据集的损失和衡量标准
	        loss_history[&quot;train&quot;].append(train_loss)
	        metric_history[&quot;train&quot;].append(train_metric)
	        
	        # 使用验证集对模型结果进行评估
	        model.eval()
	        with torch.no_grad():
	            val_loss, val_metric = loss_epoch(model, loss_func, val_dl,check)
	        
	        # 选择最好的参数模型
	        if val_loss &lt; best_loss:
	            best_loss = val_loss
	            best_model_wts = copy.deepcopy(model.state_dict())
	            
	            # 存储模型参数至本地文件
	            torch.save(model.state_dict(), weight_path)
	            if(verbose):
	                print(&quot;已经保存完训练得到的最好模型！&quot;)
	        
	        # 存储验证数据集的损失和衡量标准
	        loss_history[&quot;val&quot;].append(val_loss)
	        metric_history[&quot;val&quot;].append(val_metric)
	        
	        # 学习率筛选
	        lr_scheduler.step(val_loss)
	        if current_lr != get_lr(opt):
	            if(verbose):
	                print(&quot;已经加载完CNN模型！&quot;)
	            model.load_state_dict(best_model_wts) 
	
	        if(verbose):
	            print(f&quot;train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}&quot;)
	            print(&quot;-&quot;*10) 
	
	    # 存储模型的权重和参数数据至本地
	    model.load_state_dict(best_model_wts)
	        
	    return model, loss_history, metric_history

	params_train={
	 &quot;train&quot;: train_dl,&quot;val&quot;: val_dl,
	 &quot;epochs&quot;: 50, # 迭代 50 次
	 &quot;optimiser&quot;: optim.Adam(cnn_model.parameters(),
	                         lr=3e-4),
	 &quot;lr_change&quot;: ReduceLROnPlateau(opt,
	                                mode = 'min',
	                                factor = 0.5,
	                                patience = 20,
	                                verbose = 0),
	 &quot;loss_func&quot;: nn.NLLLoss(reduction = &quot;sum&quot;),
	 &quot;weight_path&quot;: &quot;weights.pt&quot;,
	 &quot;check&quot;: False, 
	}
	
	# 训练和验证模型
	cnn_model,loss_hist,metric_hist = train_val(cnn_model, params_train)
	# 训练参数进程
	epochs = params_train[&quot;epochs&quot;]
	
	# 绘制结果图
	fig = make_subplots(rows = 1, cols = 2, subplot_titles = ['损失值-折线图','准确率-折线图'])
	fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[&quot;train&quot;], name = '训练集的损失值'), row = 1, col = 1)
	fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[&quot;val&quot;], name = '验证集的损失值'), row = 1, col = 1)
	fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[&quot;train&quot;], name = '训练集的准确率'), row = 1, col = 2)
	fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[&quot;val&quot;], name = '验证集的准确率'), row = 1, col = 2)
	fig.update_layout(template = 'plotly_white'); fig.update_layout(margin = {&quot;r&quot;:0,&quot;t&quot;:60,&quot;l&quot;:0,&quot;b&quot;:0}, height=  300)
	fig.show()

So_CNN_model(train_list, test_list)
</code></pre><p>感谢各位友友能看到最后！附一张我超级喜欢的数学宇宙gif代表结束！</p><p><img loading=lazy src=https://www.analyticsinsight.net/wp-content/uploads/2020/09/GIF-1.gif alt=" "></p><p>The End！</p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://soso010816.github.io/posts/xgboost-python/><span class=title>« Prev Page</span><br><span>ML：Simple XGBoost With Python</span></a>
<a class=next href=https://soso010816.github.io/posts/nn-python/><span class=title>Next Page »</span><br><span>DL：Neural Network With Python</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on twitter" href="https://twitter.com/intent/tweet/?text=DL%ef%bc%9aCNN%20With%20Python&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&title=DL%ef%bc%9aCNN%20With%20Python&summary=DL%ef%bc%9aCNN%20With%20Python&source=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&title=DL%ef%bc%9aCNN%20With%20Python"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on whatsapp" href="https://api.whatsapp.com/send?text=DL%ef%bc%9aCNN%20With%20Python%20-%20https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on telegram" href="https://telegram.me/share/url?text=DL%ef%bc%9aCNN%20With%20Python&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://soso010816.github.io/>Soso's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>