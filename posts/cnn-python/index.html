<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>DL：CNN With Python | Soso's Blog</title><meta name=keywords content><meta name=description content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><meta name=author content="Soso"><link rel=canonical href=https://soso010816.github.io/posts/cnn-python/><link crossorigin=anonymous href=/assets/css/stylesheet.min.26833467d0a8d69309e10439aa8f9d66fab9e2ac88264732a9f9f62a15aefe51.css integrity="sha256-JoM0Z9Co1pMJ4QQ5qo+dZvq54qyIJkcyqfn2KhWu/lE=" rel="preload stylesheet" as=style><link rel=preload href=/head.jpg as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.e85ad0406048e8176e1c7661b25d5c69297ddfe41dc4124cf75ecb99a4f7b3d1.js integrity="sha256-6FrQQGBI6BduHHZhsl1caSl93+QdxBJM917LmaT3s9E=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://soso010816.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soso010816.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soso010816.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soso010816.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soso010816.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="DL：CNN With Python"><meta property="og:description" content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><meta property="og:type" content="article"><meta property="og:url" content="https://soso010816.github.io/posts/cnn-python/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-08-29T23:11:19+08:00"><meta property="article:modified_time" content="2022-08-29T23:11:19+08:00"><meta property="og:site_name" content="Soso's Resume"><meta name=twitter:card content="summary"><meta name=twitter:title content="DL：CNN With Python"><meta name=twitter:description content="“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soso010816.github.io/posts/"},{"@type":"ListItem","position":2,"name":"DL：CNN With Python","item":"https://soso010816.github.io/posts/cnn-python/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"DL：CNN With Python","name":"DL：CNN With Python","description":"“ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog","keywords":[],"articleBody":" “ 简单的介绍 ” 在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog为大家带来鄙人封装的卷积神经网络python代码，供大家处理基本的图片分类预测问题并将结果进行可视化，当然大家也可以根据自己需求修改代码中的parames参数，从而选择出预测效果最佳的模型。 “ CNN的基本原理 ” 关于CNN的基本介绍大家可以在 A Simple Introduction About CNN 里进行学习。\n“ python代码 ” 本次的卷积神经网络使用的pytorch包，只要求有友友所使用的训练图片数据集标记好并放至所在的文件夹目录，即可以运行鄙人的CNN函数。并且一般卷积神经网络（CNN）主要用于图像处理技术， 因此本代码针对的数据集为 jpg、png等图片数据。\n导入所需的库 pytorch、glob、numpy、sklearn、matplotlib、copy\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import torch import torch.nn as nn import torch.nn.functional as F from torch import optim from torchvision import utils from torch.optim.lr_scheduler import ReduceLROnPlateau from torchvision import datasets, models, transforms from torch.utils.data import DataLoader, Dataset import copy import glob import numpy as np import plotly.graph_objs as go import matplotlib.pyplot as plt from plotly.subplots import make_subplots from sklearn.model_selection import train_test_split %matplotlib inline 数据集的构建 CPU or CUDA\n1 2 3 4 5 6 7 8 9 10 11 # 1. 选择 CPU 还是 GPU 版的 pytorch 进行建模 device = 'cuda' if torch.cuda.is_available() else 'cpu' # 2. 设置随机种子 torch.manual_seed(816) if device =='cuda': torch.cuda.manual_seed_all(816) # 将所有图片数据的路径存储至列表中, train_dir和 test_dir为训练集图片和验证集图片所在的文件夹 train_list = glob.glob(os.path.join(train_dir,'*.jpg')) # 如果图片为png形式，则将jpg改成png即可 test_list = glob.glob(os.path.join(test_dir, '*.jpg')) # 如果有测试集则使用这行代码，否则可以删除 模型的搭建 数据增强、模型结构设计、模型的训练与保持、结果可视化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 # 3. 定义完整的 CNN 框架模型 def So_CNN_model(train_list, test_list = None): # 训练集和验证集的分割 train_list, val_list = train_test_split(train_list, test_size=0.2) # 4. 图片的预处理，图片增强 train_transforms = transforms.Compose([ transforms.Resize((224, 224)), # 设计训练图片转化为224*224图片大小，可以根据需求自行修改大小 transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), ]) val_transforms = transforms.Compose([ transforms.Resize((224, 224)), # 设计验证集图片转化为224*224图片大小 transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), ]) # 如果有测试集需要输出，则也对验证集进行图片转化增强 if test_list != None: test_transforms = transforms.Compose([ transforms.Resize((224, 224)), transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor() ]) # 5. 定义一个类进行数据转化、图片数据集的处理、以及图片的标注转化 class dataset(torch.utils.data.Dataset): def __init__(self, file_list, transform=None): self.file_list = file_list # 图片名字列表 self.transform = transform # 转化器 self.label_list = label_list # 所有的标签种类 def __len__(self): self.filelength = len(self.file_list) return self.filelength # 图片数目 # 对于本地图片的下载与标注 def __getitem__(self,idx): img_path = self.file_list[idx] img = Image.open(img_path) # 打开本地图片数据集所在的位置 img_transformed = self.transform(img) # 数据增强 label = img_path.split('/')[-1].split('.')[0] # 对图片名字分割，前提是图片名字即为标注 label = label_list.index(label) # 搜索该标签在列表中的位置，并将其进行数值标注，有几个种类数值就有几种 return img_transformed, label # 6. 定义各个类 train_data = dataset(train_list, transform=train_transforms) if test_list != None: test_data = dataset(test_list, transform=test_transforms) val_data = dataset(val_list, transform=test_transforms) # 7. 数据加载 batch_size = 100 train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle=True ) if test_list != None: test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = batch_size, shuffle=True) val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size = batch_size, shuffle=True) # 8. CNN模型架构的设计 class Cnn(nn.Module): def __init__(self): super(Cnn,self).__init__() '''以下所有层的结构参数和层数数量都可以进行需修改 可以比较参数不同产生的模型结果，从而选择最优参数''' c,h,w = params['shape_in'] # 初始 数据结构 f = params['initial_filters'] # 初始 数据转化的层数 num_classes = params['num_classes'] # 需要分类的总数 num_fc1 = params['num_fc1'] # 全连接层的第一层 dropout_rate = params['dropout_rate'] # 第一层卷积层，将3通道 c 维数据转化为 f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0 self.layer1 = nn.Sequential( nn.Conv2d(c, f, kernel_size = 3, padding=0, stride=2), nn.BatchNorm2d(f), # f 维 数据进行标准化处理 nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择 nn.MaxPool2d(2) # 池化层，2*2 矩阵大小进行池化 ) # 第一层后，转化得到的维度 h,w = findConv2dOutShape(h, w, nn.MaxPool2d(2)) h,w = h/2, w/2 # 第二层卷积层，将 f 维数据转化为 2*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0 self.layer2 = nn.Sequential( nn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2), nn.BatchNorm2d(2*f), # 2*f 维 数据进行标准化处理 nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择 nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化 ) # 第二层后，转化得到的维度 h,w = findConv2dOutShape(h, w, nn.Conv2d(f, 2*f, kernel_size=3, padding=0, stride=2)) h,w = h/2, w/2 # 第三层卷积层，将 32 维数据转化为 64 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0 self.layer3 = nn.Sequential( nn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2), nn.BatchNorm2d(4*f), # 4*f 维 数据进行标准化处理 nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择 nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化 ) # 第三层后，转化得到的维度\th,w = findConv2dOutShape(h, w, nn.Conv2d(2*f, 4*f, kernel_size=3, padding=0, stride=2)) h,w = h/2, w/2 # 第四层卷积层，将 4*f 维数据转化为 8*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0 self.layer4 = nn.Sequential( nn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2), nn.BatchNorm2d(8*f), # 8*f 维 数据进行标准化处理 nn.ReLU(), # 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择 nn.MaxPool2d(2) # 池化层，2*2矩阵大小进行池化 ) # 第四层后，转化得到的维度 h,w = findConv2dOutShape(h, w, nn.Conv2d(4*f, 8*f, kernel_size=3, padding=0, stride=2)) h,w = h/2, w/2 # 最后 我设计了2层全连接神经网络结构 self.num_flatten= h * w* 8*f self.fc1 = nn.Linear(self.num_flatten, num_fc1) self.dropout = nn.Dropout(dropout_rate) # 以 0.5 的概率对其进行剔除 self.fc2 = nn.Linear(num_fc1, num_class) self.relu = nn.ReLU() # 定义激活函数 RELU self.softmax = nn.log_softmax() # 定义 最后的输出函数 Softmax # 定义向前传播 def forward(self,x): out = self.layer1(x) out = self.layer2(out) out = self.layer3(out) out = self.layer4(out) out = out.view(-1, self.num_flatten) out = self.relu(self.fc1(out)) out = self.softmax(self.fc2(out), dim = 1) return out params_model={ \"shape_in\": (3, 224, 224), \"initial_filters\": 8, \"num_fc1\": 100, \"dropout_rate\": 0.25, \"num_classes\": len(label_list)} # num_class,根据类别的总数而定 # 传达模型结构给cnn_model cnn_model = Cnn(params_model) device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') model = cnn_model.to(device) # 9. 定义损失函数 loss_func = nn.NLLLoss(reduction=\"sum\") # 10. 定义一个优化器，优化器将保持当前状态，并根据计算的梯度更新参数 opt = optim.Adam(cnn_model.parameters(), lr=3e-4) lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1) # 11. 定义模型训练函数 def train_val(model, params,verbose=False): # 获取训练参数 epochs = params[\"epochs\"] loss_func = params[\"loss_func\"] opt = params[\"optimiser\"] train_dl = params[\"train\"] val_dl = params[\"val\"] check = params[\"check\"] lr_scheduler = params[\"lr_change\"] weight_path = params[\"weight_path\"] loss_history = {\"train\": [],\"val\": []} # 每次 epoch 的训练集和验证集的损失值 metric_history = {\"train\": [],\"val\": []} # 每次 epoch 的 metric值 best_model_wts = copy.deepcopy(model.state_dict()) # 深度复制最佳性能模型的权重 best_loss = float('inf') # 将最佳的损失值初始化为极大值 # 迭代循环 for epoch in range(epochs): # 获取学习率 current_lr = get_lr(opt) if(verbose): print('Epoch {}/{}, current lr={}'.format(epoch, epochs - 1, current_lr)) # 使用训练集训练 CNN 模型 model.train() train_loss, train_metric = loss_epoch(model,loss_func,train_dl,check,opt) # 收集训练数据集的损失和衡量标准 loss_history[\"train\"].append(train_loss) metric_history[\"train\"].append(train_metric) # 使用验证集对模型结果进行评估 model.eval() with torch.no_grad(): val_loss, val_metric = loss_epoch(model, loss_func, val_dl,check) # 选择最好的参数模型 if val_loss \u003c best_loss: best_loss = val_loss best_model_wts = copy.deepcopy(model.state_dict()) # 存储模型参数至本地文件 torch.save(model.state_dict(), weight_path) if(verbose): print(\"已经保存完训练得到的最好模型！\") # 存储验证数据集的损失和衡量标准 loss_history[\"val\"].append(val_loss) metric_history[\"val\"].append(val_metric) # 学习率筛选 lr_scheduler.step(val_loss) if current_lr != get_lr(opt): if(verbose): print(\"已经加载完CNN模型！\") model.load_state_dict(best_model_wts) if(verbose): print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\") print(\"-\"*10) # 存储模型的权重和参数数据至本地 model.load_state_dict(best_model_wts) return model, loss_history, metric_history params_train={ \"train\": train_dl,\"val\": val_dl, \"epochs\": 50, # 迭代 50 次 \"optimiser\": optim.Adam(cnn_model.parameters(), lr=3e-4), \"lr_change\": ReduceLROnPlateau(opt, mode = 'min', factor = 0.5, patience = 20, verbose = 0), \"loss_func\": nn.NLLLoss(reduction = \"sum\"), \"weight_path\": \"weights.pt\", \"check\": False, } # 训练和验证模型 cnn_model,loss_hist,metric_hist = train_val(cnn_model, params_train) # 训练参数进程 epochs = params_train[\"epochs\"] # 绘制结果图 fig = make_subplots(rows = 1, cols = 2, subplot_titles = ['损失值-折线图','准确率-折线图']) fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[\"train\"], name = '训练集的损失值'), row = 1, col = 1) fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = loss_hist[\"val\"], name = '验证集的损失值'), row = 1, col = 1) fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[\"train\"], name = '训练集的准确率'), row = 1, col = 2) fig.add_trace(go.Scatter(x = [*range(1,epochs+1)], y = metric_hist[\"val\"], name = '验证集的准确率'), row = 1, col = 2) fig.update_layout(template = 'plotly_white'); fig.update_layout(margin = {\"r\":0,\"t\":60,\"l\":0,\"b\":0}, height= 300) fig.show() So_CNN_model(train_list, test_list) 感谢各位友友能看到最后！附一张我超级喜欢的数学宇宙gif代表结束！\nThe End！\n","wordCount":"2884","inLanguage":"en","datePublished":"2022-08-29T23:11:19+08:00","dateModified":"2022-08-29T23:11:19+08:00","author":{"@type":"Person","name":"Soso"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soso010816.github.io/posts/cnn-python/"},"publisher":{"@type":"Organization","name":"Soso's Blog","logo":{"@type":"ImageObject","url":"https://soso010816.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soso010816.github.io/ accesskey=h title="Soso's Blog (Alt + H)"><img src=https://soso010816.github.io/head.jpg alt=logo aria-label=logo height=25>Soso's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://soso010816.github.io/ title="So Home"><span>So Home</span></a></li><li><a href=https://soso010816.github.io/posts/ title="📚So Posts"><span>📚So Posts</span></a></li><li><a href=https://soso010816.github.io/archive/ title="So Archive"><span>So Archive</span></a></li><li><a href=https://soso010816.github.io/search/ title="So Search (Alt + /)" accesskey=/><span>So Search</span></a></li><li><a href=https://soso010816.github.io/about/ title="👻About me"><span>👻About me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soso010816.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://soso010816.github.io/posts/>Posts</a></div><h1 class=post-title>DL：CNN With Python</h1><div class=post-meta><span title='2022-08-29 23:11:19 +0800 CST'>August 29, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Soso</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#-%e7%ae%80%e5%8d%95%e7%9a%84%e4%bb%8b%e7%bb%8d- aria-label="“ 简单的介绍 ”"><strong>“ 简单的介绍 ”</strong></a></li><li><a href=#-cnn%e7%9a%84%e5%9f%ba%e6%9c%ac%e5%8e%9f%e7%90%86- aria-label="“ CNN的基本原理 ”"><strong>“ CNN的基本原理 ”</strong></a></li><li><a href=#-python%e4%bb%a3%e7%a0%81- aria-label="“ python代码 ”"><strong>“ python代码 ”</strong></a></li></ul></div></details></div><div class=post-content><p><img loading=lazy src=https://visme.co/blog/wp-content/uploads/2019/09/interactive-presentation-header.gif alt=" "></p><h3 id=-简单的介绍-><strong>“ 简单的介绍 ”</strong><a hidden class=anchor aria-hidden=true href=#-简单的介绍->#</a></h3><blockquote><p>在统计学习中，我们也经常遇到高维数据的问题，比如图片处理，图片的处理技术在目前也是非常热门，不断被探索的领域，本次学习blog为大家带来鄙人封装的卷积神经网络python代码，供大家处理基本的图片分类预测问题并将结果进行可视化，当然大家也可以根据自己需求修改代码中的parames参数，从而选择出预测效果最佳的模型。
<img loading=lazy src=https://thumbs.gfycat.com/WhichMetallicDodo-size_restricted.gif alt=" "></p></blockquote><h3 id=-cnn的基本原理-><strong>“ CNN的基本原理 ”</strong><a hidden class=anchor aria-hidden=true href=#-cnn的基本原理->#</a></h3><blockquote><p>关于CNN的基本介绍大家可以在 <a href=https://zhuanlan.zhihu.com/p/42559190>A Simple Introduction About CNN</a> 里进行学习。</p></blockquote><h3 id=-python代码-><strong>“ python代码 ”</strong><a hidden class=anchor aria-hidden=true href=#-python代码->#</a></h3><blockquote><p>本次的卷积神经网络使用的pytorch包，只要求有友友所使用的训练图片数据集标记好并放至所在的文件夹目录，即可以运行鄙人的CNN函数。并且一般卷积神经网络（CNN）主要用于图像处理技术， 因此本代码针对的数据集为 jpg、png等图片数据。</p></blockquote><ul><li><strong>导入所需的库</strong></li></ul><blockquote><p>pytorch、glob、numpy、sklearn、matplotlib、copy</p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn <span style=color:#66d9ef>as</span> nn
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch.nn.functional <span style=color:#66d9ef>as</span> F
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch <span style=color:#f92672>import</span> optim
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> utils
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.optim.lr_scheduler <span style=color:#f92672>import</span> ReduceLROnPlateau
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, models, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torch.utils.data <span style=color:#f92672>import</span> DataLoader, Dataset
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> copy
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> glob
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> plotly.graph_objs <span style=color:#66d9ef>as</span> go
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> plotly.subplots <span style=color:#f92672>import</span> make_subplots
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.model_selection <span style=color:#f92672>import</span> train_test_split
</span></span><span style=display:flex><span><span style=color:#f92672>%</span>matplotlib inline
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>数据集的构建</strong></li></ul><blockquote><p>CPU or CUDA</p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 1. 选择 CPU 还是 GPU 版的 pytorch 进行建模</span>
</span></span><span style=display:flex><span>device <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 2. 设置随机种子</span>
</span></span><span style=display:flex><span>torch<span style=color:#f92672>.</span>manual_seed(<span style=color:#ae81ff>816</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>if</span> device <span style=color:#f92672>==</span><span style=color:#e6db74>&#39;cuda&#39;</span>:
</span></span><span style=display:flex><span>	torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>manual_seed_all(<span style=color:#ae81ff>816</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 将所有图片数据的路径存储至列表中, train_dir和 test_dir为训练集图片和验证集图片所在的文件夹</span>
</span></span><span style=display:flex><span>train_list <span style=color:#f92672>=</span> glob<span style=color:#f92672>.</span>glob(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(train_dir,<span style=color:#e6db74>&#39;*.jpg&#39;</span>)) <span style=color:#75715e># 如果图片为png形式，则将jpg改成png即可</span>
</span></span><span style=display:flex><span>test_list <span style=color:#f92672>=</span> glob<span style=color:#f92672>.</span>glob(os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(test_dir, <span style=color:#e6db74>&#39;*.jpg&#39;</span>)) <span style=color:#75715e># 如果有测试集则使用这行代码，否则可以删除</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><strong>模型的搭建</strong></li></ul><blockquote><p>数据增强、模型结构设计、模型的训练与保持、结果可视化</p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">  9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 17
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 18
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 19
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 20
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 21
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 22
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 23
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 24
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 25
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 26
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 27
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 28
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 29
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 30
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 31
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 32
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 33
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 34
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 35
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 36
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 37
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 38
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 39
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 40
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 41
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 42
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 43
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 44
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 45
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 46
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 47
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 48
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 49
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 50
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 51
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 52
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 53
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 54
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 55
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 56
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 57
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 58
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 59
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 60
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 61
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 62
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 63
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 64
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 65
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 66
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 67
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 68
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 69
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 70
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 71
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 72
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 73
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 74
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 75
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 76
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 77
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 78
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 79
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 80
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 81
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 82
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 83
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 84
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 85
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 86
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 87
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 88
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 89
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 90
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 91
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 92
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 93
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 94
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 95
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 96
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 97
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 98
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 99
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">100
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">101
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">102
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">103
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">104
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">105
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">106
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">107
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">108
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">109
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">110
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">111
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">112
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">113
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">114
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">115
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">116
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">117
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">118
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">119
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">120
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">121
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">122
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">123
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">124
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">125
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">126
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">127
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">128
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">129
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">130
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">131
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">132
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">133
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">134
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">135
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">136
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">137
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">138
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">139
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">140
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">141
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">142
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">143
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">144
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">145
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">146
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">147
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">148
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">149
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">150
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">151
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">152
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">153
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">154
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">155
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">156
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">157
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">158
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">159
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">160
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">161
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">162
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">163
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">164
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">165
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">166
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">167
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">168
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">169
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">170
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">171
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">172
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">173
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">174
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">175
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">176
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">177
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">178
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">179
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">180
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">181
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">182
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">183
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">184
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">185
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">186
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">187
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">188
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">189
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">190
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">191
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">192
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">193
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">194
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">195
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">196
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">197
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">198
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">199
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">200
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">201
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">202
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">203
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">204
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">205
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">206
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">207
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">208
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">209
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">210
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">211
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">212
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">213
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">214
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">215
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">216
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">217
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">218
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">219
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">220
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">221
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">222
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">223
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">224
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">225
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">226
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">227
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">228
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">229
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">230
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">231
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">232
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">233
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">234
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">235
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">236
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">237
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">238
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">239
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">240
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">241
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">242
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">243
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">244
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">245
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">246
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">247
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">248
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">249
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">250
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">251
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">252
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">253
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">254
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">255
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">256
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">257
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">258
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">259
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">260
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">261
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">262
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">263
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">264
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">265
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">266
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">267
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">268
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">269
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">270
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 3. 定义完整的 CNN 框架模型</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>So_CNN_model</span>(train_list, test_list <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 训练集和验证集的分割</span>
</span></span><span style=display:flex><span>	train_list, val_list <span style=color:#f92672>=</span> train_test_split(train_list, test_size<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	<span style=color:#75715e># 4. 图片的预处理，图片增强</span>
</span></span><span style=display:flex><span>	train_transforms <span style=color:#f92672>=</span>  transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>Resize((<span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>)), <span style=color:#75715e># 设计训练图片转化为224*224图片大小，可以根据需求自行修改大小</span>
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>RandomResizedCrop(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>RandomHorizontalFlip(),
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>ToTensor(),
</span></span><span style=display:flex><span>		])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	val_transforms <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>Resize((<span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>)), <span style=color:#75715e># 设计验证集图片转化为224*224图片大小</span>
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>RandomResizedCrop(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>RandomHorizontalFlip(),
</span></span><span style=display:flex><span>			transforms<span style=color:#f92672>.</span>ToTensor(),
</span></span><span style=display:flex><span>		])
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	<span style=color:#75715e># 如果有测试集需要输出，则也对验证集进行图片转化增强</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>if</span> test_list <span style=color:#f92672>!=</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>			test_transforms <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([   
</span></span><span style=display:flex><span>				transforms<span style=color:#f92672>.</span>Resize((<span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>)),
</span></span><span style=display:flex><span>				transforms<span style=color:#f92672>.</span>RandomResizedCrop(<span style=color:#ae81ff>224</span>),
</span></span><span style=display:flex><span>				transforms<span style=color:#f92672>.</span>RandomHorizontalFlip(),
</span></span><span style=display:flex><span>				transforms<span style=color:#f92672>.</span>ToTensor()
</span></span><span style=display:flex><span>				])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 5. 定义一个类进行数据转化、图片数据集的处理、以及图片的标注转化</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>dataset</span>(torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>Dataset):
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>def</span> __init__(self, file_list, transform<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>file_list <span style=color:#f92672>=</span> file_list <span style=color:#75715e># 图片名字列表</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>transform <span style=color:#f92672>=</span> transform  <span style=color:#75715e># 转化器</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>label_list <span style=color:#f92672>=</span> label_list <span style=color:#75715e># 所有的标签种类</span>
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>def</span> __len__(self):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>filelength <span style=color:#f92672>=</span> len(self<span style=color:#f92672>.</span>file_list)
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>filelength  <span style=color:#75715e># 图片数目</span>
</span></span><span style=display:flex><span>		
</span></span><span style=display:flex><span>		<span style=color:#75715e># 对于本地图片的下载与标注</span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>def</span> __getitem__(self,idx):
</span></span><span style=display:flex><span>			img_path <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>file_list[idx]
</span></span><span style=display:flex><span>			img <span style=color:#f92672>=</span> Image<span style=color:#f92672>.</span>open(img_path)  <span style=color:#75715e># 打开本地图片数据集所在的位置</span>
</span></span><span style=display:flex><span>			img_transformed <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>transform(img)  <span style=color:#75715e># 数据增强</span>
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			label <span style=color:#f92672>=</span> img_path<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;/&#39;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;.&#39;</span>)[<span style=color:#ae81ff>0</span>] <span style=color:#75715e># 对图片名字分割，前提是图片名字即为标注</span>
</span></span><span style=display:flex><span>					label <span style=color:#f92672>=</span> label_list<span style=color:#f92672>.</span>index(label) <span style=color:#75715e># 搜索该标签在列表中的位置，并将其进行数值标注，有几个种类数值就有几种</span>
</span></span><span style=display:flex><span>				
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>return</span> img_transformed, label
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 6. 定义各个类</span>
</span></span><span style=display:flex><span>	train_data <span style=color:#f92672>=</span> dataset(train_list, transform<span style=color:#f92672>=</span>train_transforms)
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>if</span> test_list <span style=color:#f92672>!=</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>			test_data <span style=color:#f92672>=</span> dataset(test_list, transform<span style=color:#f92672>=</span>test_transforms)
</span></span><span style=display:flex><span>	val_data <span style=color:#f92672>=</span> dataset(val_list, transform<span style=color:#f92672>=</span>test_transforms)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 7. 数据加载</span>
</span></span><span style=display:flex><span>	batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>	train_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(dataset <span style=color:#f92672>=</span> train_data, batch_size <span style=color:#f92672>=</span> batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span> )
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>if</span> test_list <span style=color:#f92672>!=</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>			test_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(dataset <span style=color:#f92672>=</span> test_data, batch_size <span style=color:#f92672>=</span> batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>	val_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(dataset <span style=color:#f92672>=</span> val_data, batch_size <span style=color:#f92672>=</span> batch_size, shuffle<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 8. CNN模型架构的设计</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Cnn</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>def</span> __init__(self):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>			super(Cnn,self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#e6db74>&#39;&#39;&#39;以下所有层的结构参数和层数数量都可以进行需修改
</span></span></span><span style=display:flex><span><span style=color:#e6db74>		可以比较参数不同产生的模型结果，从而选择最优参数&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		c,h,w <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#39;shape_in&#39;</span>] <span style=color:#75715e># 初始 数据结构</span>
</span></span><span style=display:flex><span>		f <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#39;initial_filters&#39;</span>] <span style=color:#75715e># 初始 数据转化的层数</span>
</span></span><span style=display:flex><span>		num_classes <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#39;num_classes&#39;</span>]  <span style=color:#75715e># 需要分类的总数</span>
</span></span><span style=display:flex><span>		num_fc1 <span style=color:#f92672>=</span>  params[<span style=color:#e6db74>&#39;num_fc1&#39;</span>] <span style=color:#75715e># 全连接层的第一层</span>
</span></span><span style=display:flex><span>		dropout_rate <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#39;dropout_rate&#39;</span>]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第一层卷积层，将3通道 c 维数据转化为 f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>layer1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>Conv2d(c, f, kernel_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>BatchNorm2d(f),  <span style=color:#75715e># f 维 数据进行标准化处理</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>ReLU(), <span style=color:#75715e># 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>) <span style=color:#75715e># 池化层，2*2 矩阵大小进行池化</span>
</span></span><span style=display:flex><span>			)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第一层后，转化得到的维度</span>
</span></span><span style=display:flex><span>			h,w <span style=color:#f92672>=</span> findConv2dOutShape(h, w, nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>		h,w <span style=color:#f92672>=</span> h<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>, w<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第二层卷积层，将 f 维数据转化为 2*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>layer2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>Conv2d(f, <span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>f), <span style=color:#75715e># 2*f 维 数据进行标准化处理</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>ReLU(), <span style=color:#75715e># 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>) <span style=color:#75715e># 池化层，2*2矩阵大小进行池化</span>
</span></span><span style=display:flex><span>				)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第二层后，转化得到的维度</span>
</span></span><span style=display:flex><span>			h,w <span style=color:#f92672>=</span> findConv2dOutShape(h, w, nn<span style=color:#f92672>.</span>Conv2d(f, <span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>		h,w <span style=color:#f92672>=</span> h<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>, w<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第三层卷积层，将 32 维数据转化为 64 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>layer3 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>f, <span style=color:#ae81ff>4</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>4</span><span style=color:#f92672>*</span>f), <span style=color:#75715e># 4*f 维 数据进行标准化处理</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>ReLU(), <span style=color:#75715e># 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>) <span style=color:#75715e># 池化层，2*2矩阵大小进行池化</span>
</span></span><span style=display:flex><span>			)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第三层后，转化得到的维度	</span>
</span></span><span style=display:flex><span>			h,w <span style=color:#f92672>=</span> findConv2dOutShape(h, w, nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>2</span><span style=color:#f92672>*</span>f, <span style=color:#ae81ff>4</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>		h,w <span style=color:#f92672>=</span> h<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>, w<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第四层卷积层，将 4*f 维数据转化为 8*f 维数据，卷积的矩阵大小为3*3，步长为2，填白大小为0</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>layer4 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>4</span><span style=color:#f92672>*</span>f, <span style=color:#ae81ff>8</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>),
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>BatchNorm2d(<span style=color:#ae81ff>8</span><span style=color:#f92672>*</span>f), <span style=color:#75715e># 8*f 维 数据进行标准化处理</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>ReLU(), <span style=color:#75715e># 激活函数为 ReLU 函数，也可以根据需要对其进行重新选择</span>
</span></span><span style=display:flex><span>				nn<span style=color:#f92672>.</span>MaxPool2d(<span style=color:#ae81ff>2</span>) <span style=color:#75715e># 池化层，2*2矩阵大小进行池化</span>
</span></span><span style=display:flex><span>			)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 第四层后，转化得到的维度</span>
</span></span><span style=display:flex><span>			h,w <span style=color:#f92672>=</span> findConv2dOutShape(h, w, nn<span style=color:#f92672>.</span>Conv2d(<span style=color:#ae81ff>4</span><span style=color:#f92672>*</span>f, <span style=color:#ae81ff>8</span><span style=color:#f92672>*</span>f, kernel_size<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>, padding<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, stride<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>))        
</span></span><span style=display:flex><span>		h,w <span style=color:#f92672>=</span> h<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>, w<span style=color:#f92672>/</span><span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 最后 我设计了2层全连接神经网络结构</span>
</span></span><span style=display:flex><span>		self<span style=color:#f92672>.</span>num_flatten<span style=color:#f92672>=</span> h <span style=color:#f92672>*</span> w<span style=color:#f92672>*</span> <span style=color:#ae81ff>8</span><span style=color:#f92672>*</span>f
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>fc1 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(self<span style=color:#f92672>.</span>num_flatten, num_fc1)  
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>dropout <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Dropout(dropout_rate) <span style=color:#75715e># 以 0.5 的概率对其进行剔除</span>
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>fc2 <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(num_fc1, num_class)
</span></span><span style=display:flex><span>			self<span style=color:#f92672>.</span>relu <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>ReLU() <span style=color:#75715e># 定义激活函数  RELU</span>
</span></span><span style=display:flex><span>		self<span style=color:#f92672>.</span>softmax <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>log_softmax() <span style=color:#75715e># 定义 最后的输出函数 Softmax</span>
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 定义向前传播</span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self,x):
</span></span><span style=display:flex><span>			out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer1(x)
</span></span><span style=display:flex><span>			out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer2(out)
</span></span><span style=display:flex><span>			out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer3(out)
</span></span><span style=display:flex><span>		out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>layer4(out)
</span></span><span style=display:flex><span>			out <span style=color:#f92672>=</span> out<span style=color:#f92672>.</span>view(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, self<span style=color:#f92672>.</span>num_flatten)
</span></span><span style=display:flex><span>			out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>relu(self<span style=color:#f92672>.</span>fc1(out))
</span></span><span style=display:flex><span>		out <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>softmax(self<span style=color:#f92672>.</span>fc2(out), dim <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>return</span> out
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	params_model<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>			<span style=color:#e6db74>&#34;shape_in&#34;</span>: (<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>), 
</span></span><span style=display:flex><span>			<span style=color:#e6db74>&#34;initial_filters&#34;</span>: <span style=color:#ae81ff>8</span>,    
</span></span><span style=display:flex><span>			<span style=color:#e6db74>&#34;num_fc1&#34;</span>: <span style=color:#ae81ff>100</span>,
</span></span><span style=display:flex><span>			<span style=color:#e6db74>&#34;dropout_rate&#34;</span>: <span style=color:#ae81ff>0.25</span>,
</span></span><span style=display:flex><span>			<span style=color:#e6db74>&#34;num_classes&#34;</span>: len(label_list)}  <span style=color:#75715e># num_class,根据类别的总数而定</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 传达模型结构给cnn_model</span>
</span></span><span style=display:flex><span>	cnn_model <span style=color:#f92672>=</span> Cnn(params_model)
</span></span><span style=display:flex><span>	device <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>device(<span style=color:#e6db74>&#39;cuda&#39;</span> <span style=color:#66d9ef>if</span> torch<span style=color:#f92672>.</span>cuda<span style=color:#f92672>.</span>is_available() <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;cpu&#39;</span>)
</span></span><span style=display:flex><span>	model <span style=color:#f92672>=</span> cnn_model<span style=color:#f92672>.</span>to(device)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 9. 定义损失函数</span>
</span></span><span style=display:flex><span>	loss_func <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>NLLLoss(reduction<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sum&#34;</span>)
</span></span><span style=display:flex><span>		
</span></span><span style=display:flex><span>	<span style=color:#75715e># 10. 定义一个优化器，优化器将保持当前状态，并根据计算的梯度更新参数</span>
</span></span><span style=display:flex><span>	opt <span style=color:#f92672>=</span> optim<span style=color:#f92672>.</span>Adam(cnn_model<span style=color:#f92672>.</span>parameters(), lr<span style=color:#f92672>=</span><span style=color:#ae81ff>3e-4</span>)
</span></span><span style=display:flex><span>	lr_scheduler <span style=color:#f92672>=</span> ReduceLROnPlateau(opt, mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;min&#39;</span>,factor<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>, patience<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>,verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#75715e># 11. 定义模型训练函数</span>
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_val</span>(model, params,verbose<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 获取训练参数</span>
</span></span><span style=display:flex><span>		epochs <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;epochs&#34;</span>]
</span></span><span style=display:flex><span>		loss_func <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;loss_func&#34;</span>]
</span></span><span style=display:flex><span>		opt <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;optimiser&#34;</span>]
</span></span><span style=display:flex><span>		train_dl <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;train&#34;</span>]
</span></span><span style=display:flex><span>		val_dl <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;val&#34;</span>]
</span></span><span style=display:flex><span>		check <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;check&#34;</span>]
</span></span><span style=display:flex><span>		lr_scheduler <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;lr_change&#34;</span>]
</span></span><span style=display:flex><span>		weight_path <span style=color:#f92672>=</span> params[<span style=color:#e6db74>&#34;weight_path&#34;</span>]
</span></span><span style=display:flex><span>	  
</span></span><span style=display:flex><span>		loss_history <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;train&#34;</span>: [],<span style=color:#e6db74>&#34;val&#34;</span>: []} <span style=color:#75715e># 每次 epoch 的训练集和验证集的损失值</span>
</span></span><span style=display:flex><span>		metric_history <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;train&#34;</span>: [],<span style=color:#e6db74>&#34;val&#34;</span>: []} <span style=color:#75715e># 每次 epoch 的 metric值</span>
</span></span><span style=display:flex><span>		best_model_wts <span style=color:#f92672>=</span> copy<span style=color:#f92672>.</span>deepcopy(model<span style=color:#f92672>.</span>state_dict()) <span style=color:#75715e># 深度复制最佳性能模型的权重</span>
</span></span><span style=display:flex><span>		best_loss <span style=color:#f92672>=</span> float(<span style=color:#e6db74>&#39;inf&#39;</span>) <span style=color:#75715e># 将最佳的损失值初始化为极大值</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>		<span style=color:#75715e># 迭代循环</span>
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(epochs):
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 获取学习率</span>
</span></span><span style=display:flex><span>			current_lr <span style=color:#f92672>=</span> get_lr(opt)
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>if</span>(verbose):
</span></span><span style=display:flex><span>				print(<span style=color:#e6db74>&#39;Epoch </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>, current lr=</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(epoch, epochs <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>, current_lr))
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 使用训练集训练 CNN 模型</span>
</span></span><span style=display:flex><span>			model<span style=color:#f92672>.</span>train()
</span></span><span style=display:flex><span>			train_loss, train_metric <span style=color:#f92672>=</span> loss_epoch(model,loss_func,train_dl,check,opt)
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>			<span style=color:#75715e># 收集训练数据集的损失和衡量标准</span>
</span></span><span style=display:flex><span>			loss_history[<span style=color:#e6db74>&#34;train&#34;</span>]<span style=color:#f92672>.</span>append(train_loss)
</span></span><span style=display:flex><span>			metric_history[<span style=color:#e6db74>&#34;train&#34;</span>]<span style=color:#f92672>.</span>append(train_metric)
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 使用验证集对模型结果进行评估</span>
</span></span><span style=display:flex><span>			model<span style=color:#f92672>.</span>eval()
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>with</span> torch<span style=color:#f92672>.</span>no_grad():
</span></span><span style=display:flex><span>				val_loss, val_metric <span style=color:#f92672>=</span> loss_epoch(model, loss_func, val_dl,check)
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 选择最好的参数模型</span>
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>if</span> val_loss <span style=color:#f92672>&lt;</span> best_loss:
</span></span><span style=display:flex><span>				best_loss <span style=color:#f92672>=</span> val_loss
</span></span><span style=display:flex><span>				best_model_wts <span style=color:#f92672>=</span> copy<span style=color:#f92672>.</span>deepcopy(model<span style=color:#f92672>.</span>state_dict())
</span></span><span style=display:flex><span>				
</span></span><span style=display:flex><span>				<span style=color:#75715e># 存储模型参数至本地文件</span>
</span></span><span style=display:flex><span>				torch<span style=color:#f92672>.</span>save(model<span style=color:#f92672>.</span>state_dict(), weight_path)
</span></span><span style=display:flex><span>				<span style=color:#66d9ef>if</span>(verbose):
</span></span><span style=display:flex><span>					print(<span style=color:#e6db74>&#34;已经保存完训练得到的最好模型！&#34;</span>)
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 存储验证数据集的损失和衡量标准</span>
</span></span><span style=display:flex><span>			loss_history[<span style=color:#e6db74>&#34;val&#34;</span>]<span style=color:#f92672>.</span>append(val_loss)
</span></span><span style=display:flex><span>			metric_history[<span style=color:#e6db74>&#34;val&#34;</span>]<span style=color:#f92672>.</span>append(val_metric)
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>			<span style=color:#75715e># 学习率筛选</span>
</span></span><span style=display:flex><span>			lr_scheduler<span style=color:#f92672>.</span>step(val_loss)
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>if</span> current_lr <span style=color:#f92672>!=</span> get_lr(opt):
</span></span><span style=display:flex><span>				<span style=color:#66d9ef>if</span>(verbose):
</span></span><span style=display:flex><span>					print(<span style=color:#e6db74>&#34;已经加载完CNN模型！&#34;</span>)
</span></span><span style=display:flex><span>				model<span style=color:#f92672>.</span>load_state_dict(best_model_wts) 
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>			<span style=color:#66d9ef>if</span>(verbose):
</span></span><span style=display:flex><span>				print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;train loss: </span><span style=color:#e6db74>{</span>train_loss<span style=color:#e6db74>:</span><span style=color:#e6db74>.6f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, dev loss: </span><span style=color:#e6db74>{</span>val_loss<span style=color:#e6db74>:</span><span style=color:#e6db74>.6f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>, accuracy: </span><span style=color:#e6db74>{</span><span style=color:#ae81ff>100</span><span style=color:#f92672>*</span>val_metric<span style=color:#e6db74>:</span><span style=color:#e6db74>.2f</span><span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>				print(<span style=color:#e6db74>&#34;-&#34;</span><span style=color:#f92672>*</span><span style=color:#ae81ff>10</span>) 
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>		<span style=color:#75715e># 存储模型的权重和参数数据至本地</span>
</span></span><span style=display:flex><span>		model<span style=color:#f92672>.</span>load_state_dict(best_model_wts)
</span></span><span style=display:flex><span>			
</span></span><span style=display:flex><span>		<span style=color:#66d9ef>return</span> model, loss_history, metric_history
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	params_train<span style=color:#f92672>=</span>{
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;train&#34;</span>: train_dl,<span style=color:#e6db74>&#34;val&#34;</span>: val_dl,
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;epochs&#34;</span>: <span style=color:#ae81ff>50</span>, <span style=color:#75715e># 迭代 50 次</span>
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;optimiser&#34;</span>: optim<span style=color:#f92672>.</span>Adam(cnn_model<span style=color:#f92672>.</span>parameters(),
</span></span><span style=display:flex><span>							 lr<span style=color:#f92672>=</span><span style=color:#ae81ff>3e-4</span>),
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;lr_change&#34;</span>: ReduceLROnPlateau(opt,
</span></span><span style=display:flex><span>									mode <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;min&#39;</span>,
</span></span><span style=display:flex><span>									factor <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.5</span>,
</span></span><span style=display:flex><span>									patience <span style=color:#f92672>=</span> <span style=color:#ae81ff>20</span>,
</span></span><span style=display:flex><span>									verbose <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>),
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;loss_func&#34;</span>: nn<span style=color:#f92672>.</span>NLLLoss(reduction <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;sum&#34;</span>),
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;weight_path&#34;</span>: <span style=color:#e6db74>&#34;weights.pt&#34;</span>,
</span></span><span style=display:flex><span>	 <span style=color:#e6db74>&#34;check&#34;</span>: <span style=color:#66d9ef>False</span>, 
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	<span style=color:#75715e># 训练和验证模型</span>
</span></span><span style=display:flex><span>	cnn_model,loss_hist,metric_hist <span style=color:#f92672>=</span> train_val(cnn_model, params_train)
</span></span><span style=display:flex><span>	<span style=color:#75715e># 训练参数进程</span>
</span></span><span style=display:flex><span>	epochs <span style=color:#f92672>=</span> params_train[<span style=color:#e6db74>&#34;epochs&#34;</span>]
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>	<span style=color:#75715e># 绘制结果图</span>
</span></span><span style=display:flex><span>	fig <span style=color:#f92672>=</span> make_subplots(rows <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, cols <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>, subplot_titles <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;损失值-折线图&#39;</span>,<span style=color:#e6db74>&#39;准确率-折线图&#39;</span>])
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>add_trace(go<span style=color:#f92672>.</span>Scatter(x <span style=color:#f92672>=</span> [<span style=color:#f92672>*</span>range(<span style=color:#ae81ff>1</span>,epochs<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)], y <span style=color:#f92672>=</span> loss_hist[<span style=color:#e6db74>&#34;train&#34;</span>], name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;训练集的损失值&#39;</span>), row <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, col <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>add_trace(go<span style=color:#f92672>.</span>Scatter(x <span style=color:#f92672>=</span> [<span style=color:#f92672>*</span>range(<span style=color:#ae81ff>1</span>,epochs<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)], y <span style=color:#f92672>=</span> loss_hist[<span style=color:#e6db74>&#34;val&#34;</span>], name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;验证集的损失值&#39;</span>), row <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, col <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>add_trace(go<span style=color:#f92672>.</span>Scatter(x <span style=color:#f92672>=</span> [<span style=color:#f92672>*</span>range(<span style=color:#ae81ff>1</span>,epochs<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)], y <span style=color:#f92672>=</span> metric_hist[<span style=color:#e6db74>&#34;train&#34;</span>], name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;训练集的准确率&#39;</span>), row <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, col <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>add_trace(go<span style=color:#f92672>.</span>Scatter(x <span style=color:#f92672>=</span> [<span style=color:#f92672>*</span>range(<span style=color:#ae81ff>1</span>,epochs<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)], y <span style=color:#f92672>=</span> metric_hist[<span style=color:#e6db74>&#34;val&#34;</span>], name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;验证集的准确率&#39;</span>), row <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>, col <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>update_layout(template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;plotly_white&#39;</span>); fig<span style=color:#f92672>.</span>update_layout(margin <span style=color:#f92672>=</span> {<span style=color:#e6db74>&#34;r&#34;</span>:<span style=color:#ae81ff>0</span>,<span style=color:#e6db74>&#34;t&#34;</span>:<span style=color:#ae81ff>60</span>,<span style=color:#e6db74>&#34;l&#34;</span>:<span style=color:#ae81ff>0</span>,<span style=color:#e6db74>&#34;b&#34;</span>:<span style=color:#ae81ff>0</span>}, height<span style=color:#f92672>=</span>  <span style=color:#ae81ff>300</span>)
</span></span><span style=display:flex><span>	fig<span style=color:#f92672>.</span>show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>So_CNN_model(train_list, test_list)
</span></span></code></pre></td></tr></table></div></div><p>感谢各位友友能看到最后！附一张我超级喜欢的数学宇宙gif代表结束！</p><p><img loading=lazy src=https://www.analyticsinsight.net/wp-content/uploads/2020/09/GIF-1.gif alt=" "></p><p>The End！</p></div><footer class=post-footer><nav class=paginav><a class=prev href=https://soso010816.github.io/posts/xgboost-python/><span class=title>« Prev Page</span><br><span>ML：Simple XGBoost With Python</span></a>
<a class=next href=https://soso010816.github.io/posts/nn-python/><span class=title>Next Page »</span><br><span>DL：Neural Network With Python</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on twitter" href="https://twitter.com/intent/tweet/?text=DL%ef%bc%9aCNN%20With%20Python&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&title=DL%ef%bc%9aCNN%20With%20Python&summary=DL%ef%bc%9aCNN%20With%20Python&source=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f&title=DL%ef%bc%9aCNN%20With%20Python"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on whatsapp" href="https://api.whatsapp.com/send?text=DL%ef%bc%9aCNN%20With%20Python%20-%20https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share DL：CNN With Python on telegram" href="https://telegram.me/share/url?text=DL%ef%bc%9aCNN%20With%20Python&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fcnn-python%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=soso010816/comments issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://soso010816.github.io/>Soso's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>