<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ML：自编码器（AutoEncoder）在降维中的作用 | Soso's Blog</title><meta name=keywords content><meta name=description content="(1) 简介 在深度学习中，自动编码器是一种无监督的神经网络模型，由编码器组件和解码器组件组成，编码器(encoder)获取输入向量并将其转换为压缩"><meta name=author content="Cheng Liu"><link rel=canonical href=https://soso010816.github.io/posts/auto-encode/><link crossorigin=anonymous href=/assets/css/stylesheet.min.26833467d0a8d69309e10439aa8f9d66fab9e2ac88264732a9f9f62a15aefe51.css integrity="sha256-JoM0Z9Co1pMJ4QQ5qo+dZvq54qyIJkcyqfn2KhWu/lE=" rel="preload stylesheet" as=style><link rel=preload href=/head.jpg as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.e85ad0406048e8176e1c7661b25d5c69297ddfe41dc4124cf75ecb99a4f7b3d1.js integrity="sha256-6FrQQGBI6BduHHZhsl1caSl93+QdxBJM917LmaT3s9E=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://soso010816.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soso010816.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soso010816.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soso010816.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soso010816.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="ML：自编码器（AutoEncoder）在降维中的作用"><meta property="og:description" content="(1) 简介 在深度学习中，自动编码器是一种无监督的神经网络模型，由编码器组件和解码器组件组成，编码器(encoder)获取输入向量并将其转换为压缩"><meta property="og:type" content="article"><meta property="og:url" content="https://soso010816.github.io/posts/auto-encode/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-09-14T14:24:19+08:00"><meta property="article:modified_time" content="2022-09-14T14:24:19+08:00"><meta property="og:site_name" content="Soso's Resume"><meta name=twitter:card content="summary"><meta name=twitter:title content="ML：自编码器（AutoEncoder）在降维中的作用"><meta name=twitter:description content="(1) 简介 在深度学习中，自动编码器是一种无监督的神经网络模型，由编码器组件和解码器组件组成，编码器(encoder)获取输入向量并将其转换为压缩"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soso010816.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ML：自编码器（AutoEncoder）在降维中的作用","item":"https://soso010816.github.io/posts/auto-encode/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ML：自编码器（AutoEncoder）在降维中的作用","name":"ML：自编码器（AutoEncoder）在降维中的作用","description":"(1) 简介 在深度学习中，自动编码器是一种无监督的神经网络模型，由编码器组件和解码器组件组成，编码器(encoder)获取输入向量并将其转换为压缩","keywords":[],"articleBody":" (1) 简介 在深度学习中，自动编码器是一种无监督的神经网络模型，由编码器组件和解码器组件组成，编码器(encoder)获取输入向量并将其转换为压缩编码（code），然后交给解码器(decoder)。解码器力求尽可能训练模型以接近并重建原始的输入向量。\n自动编码器可以用于特征降维，类似主成分分析PCA，但是其相比PCA其性能更强，在机器学习中不仅可以减少问题的维数，同时可以将数据集中的噪声去除。\n除了进行特征降维，自动编码器学习到的新特征可以送入有监督学习模型中，所以自动编码器可以起到特征提取器的作用。\n(2) 运作的过程 现在让巨弱举个简单的例子，具体说说自编码器是如何在降维中发挥作用的，以及的运作原理过程。以下图为例： 1. 先来看编码encoder部分：\nencoder 是一个降维的过程。\nInput 是每个样本的特征向量 $[x_1,x_2,x_3\\dots x_k]$ 也叫做 k 维特征向量，其中 $x_i$ 是该样本的第 i 个变量的值，code 部分为以 input 作为输入向量经过层层神经元后得到的 z 维输出向量，即也可以称为降维后的 z 维向量，z \u003c k；\n2. 再看解码decoder部分：\ndecoder是用来升至原来维度，并尽可能使升维结果与原始数据一致，以此训练出含有信息最多的最优降维输入。\n在解码部分中，模型以code（encoder输出的低维向量结果）作为decoder部分输入的特征向量，再经过 decoder 的层层神经元拟合计算，得到最终的 output向量，output的维度也为 k。\n3. 最后我们解 encoder 与 decoder结合起来看：\n在整个编码解码的过程中，神经网络以每个样本的 k 维特征向量作为输入，同样以每个样本的 k 维特征向量作为模型需要拟合的输出结果，而中间作为衔接 encoder 与 decoder 的 code 部分则是降维的结果。\n模型先将样本的 k 维特征向量进行训练输出为 z 维的 code 向量;\n以 z 维的 code 特征向量作为后半部分模型的信息输入，训练输出 output 向量与 input 的样本特征向量进行比对;\n通过损失函数最小化，不断训练两部分的神经元参数，以此得到与input 相差最小的 output 向量，此时 code 的 z 维向量即为承载着 input（样本的k维向量） 信息量最多的低维向量。\n通过自编码器训练得到的模型，我们只需取encoder部分，将样本的特征向量进行输入，即可得到承载信息量最多的 z 维向量。即达到了降维的效果。\n注意：虽然自编码器在大部分时候的降维效果都非常不错，但是该方法无法对降维后的向量赋予实际意义进行解释，只知道降维后的向量继承了原向量最多的信息量，说明该降维得到的向量对原向量具有很强的解释性。因此对于需要提供解释的问题，该类方法不太适用。\n(3) 自编码器代码如下 巨弱使用了此学期《多元统计分析》中的 case4 数据集进行试验。\n1. 导入必要库\n1 2 3 4 5 6 7 8 import matplotlib.pyplot as plt import numpy as np import pandas as pd import tensorflow as tf from tensorflow.keras.models import Model, Sequential from tensorflow.keras.layers import Dense import random from sklearn.preprocessing import StandardScaler 2. 定义一个绘制自编码器的拟合效果图函数：\n随机选择三个样本进行特征向量的原始值和模型的构建值的拟合图绘制\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 定义一个绘制自编码器的拟合效果图函数 # n_sample = 3 表示抽取3个样本进行拟合效果比较，也可以进行修改 def plot_orig_vs_recon(x_train, col_names,, xtick, autoencoder, title='', n_samples=3): fig = plt.figure(figsize=(10,6)) plt.suptitle(title) for i in range(3): plt.subplot(3, 1, i+1) idx = random.sample(range(x_train.shape[0]), 1) plt.plot(autoencoder.predict(x_train[idx]).squeeze(), label='reconstructed' if i == 0 else '') plt.plot(x_train[idx].squeeze(), label='original' if i == 0 else '') fig.axes[i].set_xticklabels(col_names) plt.xticks(np.arange(0, xtick, 1)) plt.grid(True) if i == 0: plt.legend() 3. 定义自编码器的结构：\n以下函数的参数意义为：\ndf：原始数据集；\ncol_names：需要进行降维的特征名称；\ninput_dim：输入的特征维度；\ncoder_dim：降维得到的维度；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # 定义一个绘制自编码器的拟合效果图函数 def auto_encode(df, col_names, input_dim, code_dim): df = df[col_names] x_train = df.to_numpy() # 数据标准化 scaler = StandardScaler() scaler.fit(x_train) x_train = scaler.transform(x_train) # 定义编码器与解码器（结构可以根据效果进行修改） encoder = Sequential([ Dense(64, activation='relu', input_shape=(input_dim,)), Dense(32, activation='relu'), Dense(16, activation='relu'), Dense(code_dim, activation='relu') ]) decoder = Sequential([ Dense(16, activation='relu', input_shape=(code_dim,)), Dense(32, activation='relu'), Dense(64, activation='relu'), Dense(input_dim, activation=None) ]) # 合并成自动编码器（损失函数选择均方） autoencoder = Model(inputs=encoder.input, outputs=decoder(encoder.output)) autoencoder.compile(loss='mse', optimizer='adam') # 自编码器进行训练（epoch，我这里默认了1500次，根据收敛进行修改） model_history = autoencoder.fit(x_train, x_train, epochs=1500, batch_size=32, verbose=0) # 输出损失值，并将其可视化 plt.plot(model_history.history[\"loss\"]) plt.title(\"Loss vs. Epoch\") plt.ylabel(\"Loss\") plt.xlabel(\"Epoch\") plt.grid(True) # 绘制拟合效果图 plot_orig_vs_recon(x_train, col_names, input_dim, autoencoder, title = '自编码器降维重构后的效果') # 返回得到的编码器（降维模型） return encoder, x_train 4. 使用模型输出降维结果\n以下是巨弱使用了一个巨弱本人正在上的课程《多元统计分析》中的case4案例数据集进行了测试，数据中需要降维的特征变量名为 $[x1,x2,x3,\\dots,x9]$ ，即输入维度为9，巨弱试验的降维维度为 2\n1 2 3 # 读取数据 case2 = pd.read_excel('mvstats5.xlsx', sheet_name = 'd10.2') case2.shape 结果为：(31,7)\n1 2 3 4 5 6 7 8 9 10 11 12 col_names, input_dim, code_dim = case4.columns[1:], 6, 2 # 训练模型 encoder, x_train = auto_encode(case4, col_names, input_dim, code_dim) # 输出降维结果 encoded_x_train = encoder(x_train) # 可视化降至2维的特征结果 plt.figure(figsize=(6,6)) plt.scatter(encoded_x_train[:, 0], encoded_x_train[:, 1], alpha=.8) plt.xlabel('Latent Dimension 1') plt.ylabel('Latent Dimension 2') 下图为训练过程终损失值的变化，可以看出损失值最终收敛于很小的数值\n下图为自动编码器重构数据集后与原数据的拟合对比图，可以看出重构的效果非常不错，说明降维后的数据保存了原数据的大部分信息量。\n下图为自动编码器对数据集进行降维后，得到的 2 维散点图。\n(4) 其他类型的自编码器 机器学习中除了以上传统的自编码器外，还有两种更为高级的自编码器，但是巨弱认为在一般的统计实验中使用传统的自编码器完全够用\n1. 卷积自编码器\n卷积自编码器使用卷积层和池化层替代了原来的全连接层，能够对高维图像进行处理降维，并且尽可能少的减少信息损失。\n传统自编码器一般使用的是全连接层，对于一维信号并没有信息损的影响，而对二维图像，全连接层会损失空间信息，因此相对于传统自编码器，卷积自编码器能够通过卷积操作，很好的保留二维信号的空间信息。\n2. 正则自编码器（去噪编码器）\n去噪自编码器是一类接受损坏数据作为输入，并训练来预测原始未受损数据作为输出的自编码器（相当于增加了正则项）。\n在将输入传递到网络之前添加噪声，因此如果它是图像，也许你添加了模糊，然后你让网络学习如何消除你刚刚增加的噪声并重建原始输入，这样重建误差就会稍微变小。去噪自动编码器可以通过卷积层来增强，以产生更有效的结果。\n(5) PCA与自编码器的简单对比 自动编码器和 PCA 都可以用作降维技术。但是两者之间存在一些差异：\n根据定义，PCA 是一种线性变换，而 auto-encoder 能够对复杂的非线性函数进行建模。然而，内核 PCA可以对非线性数据进行建模。 在 PCA 中，根据定义，特征是线性不相关的，它们是正交基础上的投影。相反，自动编码的特征可能是相关的。这两个优化目标完全不同（当数据投影到其上时最大化方差的正交基与最大精度重建）。 ","wordCount":"2522","inLanguage":"en","datePublished":"2022-09-14T14:24:19+08:00","dateModified":"2022-09-14T14:24:19+08:00","author":{"@type":"Person","name":"Cheng Liu"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soso010816.github.io/posts/auto-encode/"},"publisher":{"@type":"Organization","name":"Soso's Blog","logo":{"@type":"ImageObject","url":"https://soso010816.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soso010816.github.io/ accesskey=h title="Soso's Blog (Alt + H)"><img src=https://soso010816.github.io/head.jpg alt=logo aria-label=logo height=25>Soso's Blog</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://soso010816.github.io/ title="So Home"><span>So Home</span></a></li><li><a href=https://soso010816.github.io/posts/ title="📚So Posts"><span>📚So Posts</span></a></li><li><a href=https://soso010816.github.io/archive/ title="So Archive"><span>So Archive</span></a></li><li><a href=https://soso010816.github.io/search/ title="So Search (Alt + /)" accesskey=/><span>So Search</span></a></li><li><a href=https://soso010816.github.io/about/ title="👻About me"><span>👻About me</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soso010816.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://soso010816.github.io/posts/>Posts</a></div><h1 class=post-title>ML：自编码器（AutoEncoder）在降维中的作用</h1><div class=post-meta><span title='2022-09-14 14:24:19 +0800 CST'>September 14, 2022</span>&nbsp;·&nbsp;6 min&nbsp;·&nbsp;Cheng Liu</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-%e7%ae%80%e4%bb%8b aria-label="(1) 简介">(1) 简介</a></li><li><a href=#2-%e8%bf%90%e4%bd%9c%e7%9a%84%e8%bf%87%e7%a8%8b aria-label="(2) 运作的过程">(2) 运作的过程</a></li><li><a href=#3-%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%e4%bb%a3%e7%a0%81%e5%a6%82%e4%b8%8b aria-label="(3) 自编码器代码如下">(3) 自编码器代码如下</a></li><li><a href=#4-%e5%85%b6%e4%bb%96%e7%b1%bb%e5%9e%8b%e7%9a%84%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8 aria-label="(4) 其他类型的自编码器">(4) 其他类型的自编码器</a></li><li><a href=#5-pca%e4%b8%8e%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%e7%9a%84%e7%ae%80%e5%8d%95%e5%af%b9%e6%af%94 aria-label="(5) PCA与自编码器的简单对比">(5) PCA与自编码器的简单对比</a></li></ul></div></details></div><div class=post-content><p><img loading=lazy src=https://trapay.net/upload/images/block-chain2.jpg alt></p><h3 id=1-简介>(1) 简介<a hidden class=anchor aria-hidden=true href=#1-简介>#</a></h3><p>在深度学习中，<strong>自动编码器</strong>是一种无监督的神经网络模型，由<strong>编码器组件和解码器组件</strong>组成，编码器(encoder)获取输入向量并将其转换为压缩编码（code），然后交给解码器(decoder)。解码器力求尽可能训练模型以接近并<strong>重建</strong>原始的输入向量。</p><p>自动编码器可以用于特征降维，类似主成分分析PCA，但是其相比PCA其性能更强，在机器学习中不仅可以减少问题的维数，同时可以<strong>将数据集中的噪声去除</strong>。</p><p>除了进行特征降维，自动编码器学习到的新特征可以送入有监督学习模型中，所以自动编码器可以起到<strong>特征提取器</strong>的作用。</p><h3 id=2-运作的过程>(2) 运作的过程<a hidden class=anchor aria-hidden=true href=#2-运作的过程>#</a></h3><p>现在让巨弱举个简单的例子，具体说说自编码器是如何在<strong>降维</strong>中发挥作用的，以及的运作原理过程。以下图为例：
<img loading=lazy src=https://s2.loli.net/2022/09/14/uAnTd5Uvpaw3BoS.png alt=autoencode.png></p><p><strong>1. 先来看编码encoder部分：</strong></p><blockquote><p>encoder 是一个降维的过程。</p></blockquote><p>Input 是每个样本的特征向量 $[x_1,x_2,x_3\dots x_k]$ 也叫做 k 维特征向量，其中 $x_i$ 是该样本的第 <strong>i</strong> 个变量的值，code 部分为以 input 作为输入向量经过层层神经元后得到的 z 维输出向量，即也可以称为降维后的 z 维向量，<strong>z &lt; k</strong>；</p><p><strong>2. 再看解码decoder部分：</strong></p><blockquote><p>decoder是用来<strong>升至原来维度</strong>，并尽可能使升维结果与原始数据一致，以此训练出含有信息最多的最优降维输入。</p></blockquote><p>在解码部分中，模型以code（encoder输出的低维向量结果）作为decoder部分输入的特征向量，再经过 decoder 的层层神经元拟合计算，得到最终的 output向量，output的维度也为 k。</p><p><strong>3. 最后我们解 encoder 与 decoder结合起来看：</strong></p><p>在整个编码解码的过程中，神经网络以每个样本的 k 维特征向量作为输入，同样以每个样本的 k 维特征向量作为模型需要拟合的输出结果，而中间作为衔接 encoder 与 decoder 的 code 部分则是降维的结果。</p><ol><li><p>模型先将样本的 <strong>k</strong> 维特征向量进行训练输出为 <strong>z</strong> 维的 code 向量;</p></li><li><p>以 z 维的 code 特征向量作为后半部分模型的<strong>信息输入</strong>，训练输出 output 向量与 input 的样本特征向量进行比对;</p></li><li><p>通过<strong>损失函数最小化</strong>，不断训练两部分的神经元参数，以此得到与input 相差最小的 output 向量，此时 code 的 z 维向量即为承载着 input（样本的k维向量） <strong>信息量最多</strong>的低维向量。</p></li><li><p>通过自编码器训练得到的模型，我们只需取<strong>encoder</strong>部分，将样本的特征向量进行输入，即可得到承载信息量最多的 z 维向量。即达到了降维的效果。</p></li></ol><blockquote><p><strong>注意：<strong>虽然自编码器在大部分时候的降维效果都非常不错，但是该方法</strong>无法对降维后的向量赋予实际意义进行解释</strong>，只知道降维后的向量继承了原向量最多的信息量，说明该降维得到的向量对原向量具有很强的解释性。因此对于<strong>需要提供解释的问题，该类方法不太适用。</strong></p></blockquote><h3 id=3-自编码器代码如下>(3) 自编码器代码如下<a hidden class=anchor aria-hidden=true href=#3-自编码器代码如下>#</a></h3><blockquote><p>巨弱使用了此学期《多元统计分析》中的 <code>case4</code> 数据集进行试验。</p></blockquote><p><strong>1. 导入必要库</strong></p><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> matplotlib.pyplot <span style=color:#66d9ef>as</span> plt
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> pandas <span style=color:#66d9ef>as</span> pd
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> tensorflow <span style=color:#66d9ef>as</span> tf
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.models <span style=color:#f92672>import</span> Model, Sequential
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> tensorflow.keras.layers <span style=color:#f92672>import</span> Dense
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> random
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> sklearn.preprocessing <span style=color:#f92672>import</span> StandardScaler
</span></span></code></pre></td></tr></table></div></div><p><strong>2. 定义一个绘制自编码器的拟合效果图函数：</strong></p><blockquote><p>随机选择<code>三个样本</code>进行特征向量的原始值和模型的构建值的拟合图绘制</p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 定义一个绘制自编码器的拟合效果图函数</span>
</span></span><span style=display:flex><span><span style=color:#75715e># n_sample = 3 表示抽取3个样本进行拟合效果比较，也可以进行修改</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>plot_orig_vs_recon</span>(x_train, col_names,, xtick, autoencoder, title<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;&#39;</span>, n_samples<span style=color:#f92672>=</span><span style=color:#ae81ff>3</span>):
</span></span><span style=display:flex><span>    fig <span style=color:#f92672>=</span> plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>10</span>,<span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>suptitle(title)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>3</span>):
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>subplot(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>, i<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        idx <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>sample(range(x_train<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]), <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>plot(autoencoder<span style=color:#f92672>.</span>predict(x_train[idx])<span style=color:#f92672>.</span>squeeze(),
</span></span><span style=display:flex><span>                                     label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;reconstructed&#39;</span> <span style=color:#66d9ef>if</span> i <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>plot(x_train[idx]<span style=color:#f92672>.</span>squeeze(), label<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;original&#39;</span> <span style=color:#66d9ef>if</span> i <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>else</span> <span style=color:#e6db74>&#39;&#39;</span>)
</span></span><span style=display:flex><span>        fig<span style=color:#f92672>.</span>axes[i]<span style=color:#f92672>.</span>set_xticklabels(col_names)
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>xticks(np<span style=color:#f92672>.</span>arange(<span style=color:#ae81ff>0</span>, xtick, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>        plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> i <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>: 
</span></span><span style=display:flex><span>            plt<span style=color:#f92672>.</span>legend()
</span></span></code></pre></td></tr></table></div></div><p><strong>3. 定义自编码器的结构：</strong></p><p>以下函数的参数意义为：</p><ul><li><p><code>df</code>：原始数据集；</p></li><li><p><code>col_names</code>：需要进行降维的特征名称；</p></li><li><p><code>input_dim</code>：输入的特征维度；</p></li><li><p><code>coder_dim</code>：降维得到的维度；</p></li></ul><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 定义一个绘制自编码器的拟合效果图函数</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>auto_encode</span>(df, col_names, input_dim, code_dim):
</span></span><span style=display:flex><span>    df <span style=color:#f92672>=</span> df[col_names]
</span></span><span style=display:flex><span>    x_train <span style=color:#f92672>=</span> df<span style=color:#f92672>.</span>to_numpy()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 数据标准化</span>
</span></span><span style=display:flex><span>    scaler <span style=color:#f92672>=</span> StandardScaler()
</span></span><span style=display:flex><span>    scaler<span style=color:#f92672>.</span>fit(x_train)
</span></span><span style=display:flex><span>    x_train <span style=color:#f92672>=</span> scaler<span style=color:#f92672>.</span>transform(x_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 定义编码器与解码器（结构可以根据效果进行修改）</span>
</span></span><span style=display:flex><span>    encoder <span style=color:#f92672>=</span> Sequential([
</span></span><span style=display:flex><span>        Dense(<span style=color:#ae81ff>6</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(input_dim,)),
</span></span><span style=display:flex><span>        Dense(code_dim, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    decoder <span style=color:#f92672>=</span> Sequential([
</span></span><span style=display:flex><span>        Dense(<span style=color:#ae81ff>6</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(code_dim,)),
</span></span><span style=display:flex><span>        Dense(input_dim, activation<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>)
</span></span><span style=display:flex><span>    ])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 合并成自动编码器（损失函数选择均方）</span>
</span></span><span style=display:flex><span>    autoencoder <span style=color:#f92672>=</span> Model(inputs<span style=color:#f92672>=</span>encoder<span style=color:#f92672>.</span>input, outputs<span style=color:#f92672>=</span>decoder(encoder<span style=color:#f92672>.</span>output))
</span></span><span style=display:flex><span>    autoencoder<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;mse&#39;</span>, optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 自编码器进行训练（epoch，我这里默认了1500次，根据收敛进行修改）</span>
</span></span><span style=display:flex><span>    model_history <span style=color:#f92672>=</span> autoencoder<span style=color:#f92672>.</span>fit(x_train, x_train, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>1500</span>, batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>, verbose<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 输出损失值，并将其可视化</span>
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>plot(model_history<span style=color:#f92672>.</span>history[<span style=color:#e6db74>&#34;loss&#34;</span>])
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>title(<span style=color:#e6db74>&#34;Loss vs. Epoch&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#34;Loss&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#34;Epoch&#34;</span>)
</span></span><span style=display:flex><span>    plt<span style=color:#f92672>.</span>grid(<span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 绘制拟合效果图</span>
</span></span><span style=display:flex><span>    plot_orig_vs_recon(x_train, col_names, input_dim, autoencoder, title <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;自编码器降维重构后的效果&#39;</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># 返回得到的编码器（降维模型）</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> encoder, x_train
</span></span></code></pre></td></tr></table></div></div><p><strong>4. 使用模型输出降维结果</strong></p><blockquote><p>以下是巨弱使用了一个巨弱本人正在上的课程《多元统计分析》中的<code>case4</code>案例数据集进行了测试，数据中需要降维的特征变量名为 $[x1,x2,x3,\dots,x9]$ ，即输入维度为<code>9</code>，巨弱试验的降维维度为 <code>2</code></p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 读取数据</span>
</span></span><span style=display:flex><span>case2 <span style=color:#f92672>=</span> pd<span style=color:#f92672>.</span>read_excel(<span style=color:#e6db74>&#39;mvstats5.xlsx&#39;</span>, sheet_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;d10.2&#39;</span>)
</span></span><span style=display:flex><span>case2<span style=color:#f92672>.</span>shape
</span></span></code></pre></td></tr></table></div></div><blockquote><p>结果为：<code>(31,7)</code></p></blockquote><div class=highlight><div style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><table style=border-spacing:0;padding:0;margin:0;border:0><tr><td style=vertical-align:top;padding:0;margin:0;border:0><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11
</span><span style="white-space:pre;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12
</span></code></pre></td><td style=vertical-align:top;padding:0;margin:0;border:0;width:100%><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>col_names, input_dim, code_dim <span style=color:#f92672>=</span> case4<span style=color:#f92672>.</span>columns[<span style=color:#ae81ff>1</span>:], <span style=color:#ae81ff>6</span>, <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 训练模型</span>
</span></span><span style=display:flex><span>encoder, x_train <span style=color:#f92672>=</span>  auto_encode(case4, col_names, input_dim, code_dim)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 输出降维结果</span>
</span></span><span style=display:flex><span>encoded_x_train <span style=color:#f92672>=</span> encoder(x_train)
</span></span><span style=display:flex><span><span style=color:#75715e># 可视化降至2维的特征结果</span>
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>figure(figsize<span style=color:#f92672>=</span>(<span style=color:#ae81ff>6</span>,<span style=color:#ae81ff>6</span>))
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>scatter(encoded_x_train[:, <span style=color:#ae81ff>0</span>], encoded_x_train[:, <span style=color:#ae81ff>1</span>], alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>.8</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>xlabel(<span style=color:#e6db74>&#39;Latent Dimension 1&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#f92672>.</span>ylabel(<span style=color:#e6db74>&#39;Latent Dimension 2&#39;</span>)
</span></span></code></pre></td></tr></table></div></div><blockquote><p>下图为训练过程终损失值的变化，可以看出损失值最终收敛于很小的数值</p></blockquote><p><img loading=lazy src=https://s2.loli.net/2022/09/14/BdqPA5EMsZIFlTX.png#center alt=损失值.png></p><blockquote><p>下图为自动编码器重构数据集后与原数据的拟合对比图，可以看出重构的效果非常不错，说明降维后的数据保存了原数据的大部分信息量。</p></blockquote><p><img loading=lazy src=https://s2.loli.net/2022/09/14/2orYJETCNm5VQv9.png#center alt=autoencoder拟合.png></p><blockquote><p>下图为自动编码器对数据集进行降维后，得到的 2 维散点图。</p></blockquote><p><img loading=lazy src=https://s2.loli.net/2022/09/14/UHGPCztXExprfDq.png#center alt=autoencoder降维.png></p><h3 id=4-其他类型的自编码器>(4) 其他类型的自编码器<a hidden class=anchor aria-hidden=true href=#4-其他类型的自编码器>#</a></h3><blockquote><p>机器学习中除了以上传统的自编码器外，还有两种更为高级的自编码器，但是巨弱认为在一般的统计实验中使用传统的自编码器完全够用</p></blockquote><p><strong>1. 卷积自编码器</strong></p><p>卷积自编码器使用卷积层和池化层替代了原来的全连接层，能够对高维图像进行处理降维，并且尽可能少的减少信息损失。</p><p>传统自编码器一般使用的是全连接层，对于一维信号并没有信息损的影响，而对二维图像，全连接层会损失空间信息，因此相对于传统自编码器，卷积自编码器能够通过卷积操作，很好的保留二维信号的空间信息。</p><p><strong>2. 正则自编码器（去噪编码器）</strong></p><p>去噪自编码器是一类接受损坏数据作为输入，并训练来预测原始未受损数据作为输出的自编码器（相当于增加了正则项）。</p><p>在将输入传递到网络之前添加噪声，因此如果它是图像，也许你添加了模糊，然后你让网络学习如何消除你刚刚增加的噪声并重建原始输入，这样重建误差就会稍微变小。去噪自动编码器可以通过卷积层来增强，以产生更有效的结果。</p><h3 id=5-pca与自编码器的简单对比>(5) PCA与自编码器的简单对比<a hidden class=anchor aria-hidden=true href=#5-pca与自编码器的简单对比>#</a></h3><p>自动编码器和 PCA 都可以用作降维技术。但是两者之间存在一些差异：</p><ul><li>根据定义，PCA 是一种<strong>线性变换</strong>，而 auto-encoder 能够对复杂的<strong>非线性函数</strong>进行建模。然而，内核 PCA可以对非线性数据进行建模。</li><li>在 PCA 中，根据定义，特征是<strong>线性不相关</strong>的，它们是正交基础上的投影。相反，自动编码的特征<strong>可能是相关的</strong>。这两个优化<strong>目标完全不同</strong>（当数据投影到其上时最大化方差的正交基与最大精度重建）。</li></ul></div><footer class=post-footer><nav class=paginav><a class=next href=https://soso010816.github.io/posts/tm-tree2/><span class=title>Next Page »</span><br><span>ML|TS：Reflections on Tree models in Time Series</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on twitter" href="https://twitter.com/intent/tweet/?text=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f&title=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8&summary=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8&source=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f&title=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on whatsapp" href="https://api.whatsapp.com/send?text=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8%20-%20https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share ML：自编码器（AutoEncoder）在降维中的作用 on telegram" href="https://telegram.me/share/url?text=ML%ef%bc%9a%e8%87%aa%e7%bc%96%e7%a0%81%e5%99%a8%ef%bc%88AutoEncoder%ef%bc%89%e5%9c%a8%e9%99%8d%e7%bb%b4%e4%b8%ad%e7%9a%84%e4%bd%9c%e7%94%a8&url=https%3a%2f%2fsoso010816.github.io%2fposts%2fauto-encode%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=soso010816/comments issue-term=pathname label=Comment theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2022 <a href=https://soso010816.github.io/>Soso's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerText="copy";function s(){t.innerText="copied!",setTimeout(()=>{t.innerText="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
